-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108063204
  name_of_your_project: Füd-Füd
  give_a_one_sentence_description_of_your_project: Our website will crowdsource food delivery.
  what_problem_does_it_solve: It solves the problem of a demand for food delivery from restaurants that do not offer a delivery option.
  what_similar_projects_exist: Instacart is the closest thing.  They are still different, however.  Instacart hires employees and handles delivery of groceries, alcohol, and other bulk purchase items, but crucially not already made food.
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: It will likely be college students look for food, money, or both.
  how_will_you_incentivize_them_to_participate: Those who deliver food will get the bonus of working whenever they want to, delivering joy to those in their community, and of course the delivery fee.  Those who order food will get their food delivered to their door, at the time they want it, and for an agreed upon delivery fee.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: Some will provide the delivery service, needing only the skill of buying food and walking to an address.  Others will provide the demand for food, and they need nothing but an appetite and laziness.
  how_will_you_ensure_the_quality_of_the_crowd_provides: Quality will be ensured by ratings that delivery users will rate customers on a few metrics, and customers will rate aspects of the delivery process.
  how_will_you_aggregate_the_results_from_the_crowd: Results from the crowd will be used to filter feeds for both the delivery user, and customers so that poorly rated users won't be matched again.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: To begin with, users can either post requests for food deliveries, or post opportunities for others to get food delivered.  If there is a match between users looking for food, and users going to get food soon, then they will be automatically asked to settle on a delivery fee.  Once this is set, delivery users will go buy the food and deliver it to the customer who will pay the delivery person on venmo.  Then, the customers will be asked to rate the delivery person on quality, speed, price, and kindness.  The delivery user will then be asked to rank the customer on clarity of request, fairness of the pay, and kindness.
  how_will_you_evaluate_if_your_project_is_successful: Our project is successful if users from both sides of the service can sign up, log in, post requests and opportunities, fulfill requests, deliver, accept delivery fees, and rate their experience.  This will determine a successful project, but a successful business would need to create a platform with steady demand and supply.
  what_potential_problems_do_you_foresee_when_implementing_your_project: Not finding enough users to build demand or supply.  Having difficulty implementing all of the above features in time for the project's completion.  Communicating the benefits to both types of users.  Figuring out the payment flow might also prove difficult.  Ensuring quality will also be hard to do.
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108065224
  name_of_your_project: Planet Photo
  give_a_one_sentence_description_of_your_project: Crowd sourced geo-tagging of images across the world
  what_problem_does_it_solve: People can explore breathtaking photography and find places they've never been to in the world. They can possibly find places to visit, pictures to buy, and photographers to follow. <p>Photographers can display their work to a wide audience and potentially earn money.
  what_similar_projects_exist: Flickr, google images.
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: Photographers and regular people
  how_will_you_incentivize_them_to_participate: Photographers will be incentivized to participate because they'd get a platform for people to view their images and increase traffic to their own blogs or earn money.<p>Regular people are incentivized to view and like because the images are beautiful and they can explore the world while sitting at home.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: Photographers will provide images and a tagged location. They need photo taking and editing skills.
  how_will_you_ensure_the_quality_of_the_crowd_provides: Check for resolution and other image attributes.<p>Downvoted photos can be hidden or images can be flagged as inappropriate by users. 
  how_will_you_aggregate_the_results_from_the_crowd: Upvotes and downvotes will be secretly aggregated to determine order of images in the search. <p>You can search for Philadelphia, and get specific images, or PA and get images from all over PA including the Philly images sorted by votes.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: Step 1&#58; Photographers upload images and tag the location.<p>Step 2&#58; Users search for locations and view images (also vote and possibly purchase prints)<p>Step 3&#58; Our algorithm sorts images in a location by clout. <p>Step 4&#58; Machine learning algorithm recommends new locations based on user votes. 
  how_will_you_evaluate_if_your_project_is_successful: The project is successful if there is a good volume of contributors, locations have many high resolution images, and there is high upvote activity and usage per user.
  what_potential_problems_do_you_foresee_when_implementing_your_project: Potential problems are in starting off. There will initially be only few tagged places to search from. If the photographer increase quickly, the viewership can increase fairly quickly too.
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108064512
  name_of_your_project: DressedUp!
  give_a_one_sentence_description_of_your_project: DressedUp helps you locate any clothes,shoes,jewellery that you may see someone wearing.
  what_problem_does_it_solve: We often tend to see a great bag or a pair of shoes worn by someone else but have no idea where to buy it.It's not always easy to ask the person, or to determine the brand.<p>Now, with this app, all you have to do is take a picture of the item and post it.<p>Then sit back and watch companies fight to give you the best price.
  what_similar_projects_exist: The supply chain side is similar to amazon or Ebay.
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: All members of society as well as local/international businesses.
  how_will_you_incentivize_them_to_participate: The incentive for the people posting is that they want what they have already seen.<p>The incentive for the brands and businesses is they want to sell the goods to the customers.<p>Also the businesses want to market their products and study fashion trends.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: They provide the pieces of clothing,shoes,jewellery needed.<p>
  how_will_you_ensure_the_quality_of_the_crowd_provides: Guarantee quality of the product. If the businesses does not sell quality product their rating on the app will fall.<p>If it is very bad, the company will be banned from using the app.<p>However, user reviews and ratings should ensure goods are of high standard.
  how_will_you_aggregate_the_results_from_the_crowd: You can aggregate results by best reviewed users, users close to your location, or users with highest number of purchase orders etc.<p>
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: For Users<p>1) Take the picture<p>2) Upload it<p>3)Dressed Up finds it for you.<p>For Businesses<p>1) Upload the images of your products, fill out a brief description.<p>2) Dressed Up finds customers who want similar products.<p>
  how_will_you_evaluate_if_your_project_is_successful: I will evaluate it by number of orders coming on Dressed Up, also by number of hits the website gets and the total amount of revenue the website generates.<p>
  what_potential_problems_do_you_foresee_when_implementing_your_project: Initially marketing the app and making people begin using it.<p>Writing code to match products.<p>Dealing with cases where companies provide bad or no products.<p>How much commission to charge on every transaction.<p>Implementing a system similar to amazon prime with free delivery.
-
  provide_a_link_to_your_vimeo_video: http://vimeo.com/108338175.
  name_of_your_project: Food Trafficking
  give_a_one_sentence_description_of_your_project: A platform that publishes crowdsourced data about the traffic of restaurants/cafes/food trucks around Penn’s campus
  what_problem_does_it_solve: Students will no longer have to wait in extremely long lines at food trucks or experience long wait times at their favorite restaurants or be disappointed as they show up to a very crowded cafe. Food trafficking will help solve this as you will be able to see realtime updates about how crowded a certain is at all times.
  what_similar_projects_exist: Yelp
  what_type_of_project_is_it: A tool for crowdsourcing
  who_will_be_the_members_of_your_crowd: Hungry students and food fanatics
  how_will_you_incentivize_them_to_participate: It will be similar to Yelp's incentive program. People will enjoy helping each other as they want to be able to use this platform when they need it. We will also have a similar elite status for people that have contributed a lot to the platform.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: They will provide a realtime ranking of how crowded a place is currently. It does not require other skills other than the ability to be able to access the platform.
  how_will_you_ensure_the_quality_of_the_crowd_provides: The crowd will be Penn students and we will use email/facebook profile confirmation for quality assurance. 
  how_will_you_aggregate_the_results_from_the_crowd: It will be aggregated on a web/mobile platform and updated each time a contributor contributes.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: Contributors will sign in and be able to submit a ranking of the traffic of the restaurant they are in. The platform will average out all contributors's rankings within the past 15 minutes to get the most accurate results. 
  how_will_you_evaluate_if_your_project_is_successful: It can be evaluated by the number of people that are signed up to use it and the number of people that are contributors. It will also be evaluated by the accurately of the platform.
  what_potential_problems_do_you_foresee_when_implementing_your_project: A problem might occur if there aren't enough contributors. Another problem can occur if too many people are using the platform. We need to be able to scale the application.
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108194597
  name_of_your_project: Critic Critic
  give_a_one_sentence_description_of_your_project: It will compare media representation based on political party, age, gender, or race.
  what_problem_does_it_solve: There are inconsistencies in how people of different walks of life are described for the same actions or beliefs. However, when these inconsistencies are addressed, it is written off as a small-scale problem with one news network or anchor. Compiling a large volume of data about these representations could help to address media bias and unfair representation. <p>For an explicit example&#58;<p>http://thedailyshow.cc.com/videos/09yfp5/the-broads-must-be-crazy---belittled-women
  what_similar_projects_exist: Miss Representation is a documentary that discusses how men and women are portrayed differently in politics, but it draws on a lot of anecdotal evidence, and does not discuss political parties, age, or race. 
  what_type_of_project_is_it: Human computation algorithm, Social science experiment with the crowd
  who_will_be_the_members_of_your_crowd: Crowdflower Workers
  how_will_you_incentivize_them_to_participate: We will pay them money. 
  what_will_they_provide_and_what_sort_of_skills_do_they_need: They will provide an assessment of the demographic background and the name of the subject of an article. They need to be able to read in English, as we will be focusing on American media. 
  how_will_you_ensure_the_quality_of_the_crowd_provides: We will create a volume of test data to quiz them, and then cross-check their answers with known data about popular politicians. If they identify Barack Obama as a young white female, we can discard their responses. 
  how_will_you_aggregate_the_results_from_the_crowd: We will use their identifications of, for example, black politicians, to run our feature-maker and gather our most commonly used descriptors. If there is conflict over the subject (i.e., multiple politicians referenced equally), we will not use that article in our responses. 
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: Step one&#58; crawl the web (can we borrow your web crawler?) for articles about politicians. <p>Step two&#58; ask crowdflower workers to identify the demographics of the subject of each article. <p>Step three&#58; sort (via the spreadsheet produced by crowdflower) the articles into demographic groups (male vs. female, black vs. white vs. Hispanic)<p>Step four&#58; run our script to extract features on each separate set<p>Step five&#58; look at the results
  how_will_you_evaluate_if_your_project_is_successful: If we have comprehensible keywords for each group that are useful for analysis (not stopwords), we will consider it a success. <p>If our data indicates that the same words are used along party lines, or across gender lines, we'll consider that a success for humanity and chalk media bias up to isolated incidences. 
  what_potential_problems_do_you_foresee_when_implementing_your_project: Articles that mention multiple politicians will confuse the crowd. The crowd may be unable to identify a subject's political party by the context of an article if the source assumes familiarity with this information. Focusing on American politics will probably limit crowd familiarity, and may limit effectiveness of the crowd if they are rushing through the articles. 
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108278661
  name_of_your_project: PennRepairs
  give_a_one_sentence_description_of_your_project: 	A crowdsourced way to report broken lights, heaters, and other important objects around Penn facilities. 
  what_problem_does_it_solve: 	As an institution that charges a high rate of tuition, it would be embarrassing for prospective students to walk around campus and see broken items and embellishments, especially inside major buildings. For current administrators and students, the process to file a service request is often obtuse and varies from building to building. This would offer a centralized service that anyone with a camera phone can use. <p>
  what_similar_projects_exist: iFixIt (www.ifixit.com) is a crowdsourced repair manual that covers many common items such as phones, televisions, bicycles, etc. This is more focused on self-repair than the reporting of public repairs. WhoCanFixMyCar.com is a service that matches people with broken cars to people who can service their car for their specific problem. Commercial enterprises like Amazon have services where a customer can take a picture of an item if it is broken and send it into customer service.<p>
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: Penn students + Crowdflower workers
  how_will_you_incentivize_them_to_participate: Hopefully, the civic duty that Penn students feel towards maintaining the campus, in addition to the desire to not send formal requests to faculty services, will encourage them to send in pictures. If we do not get adequate participation, we can always pivot to scraping images from the web with the necessary location metadata. Obviously, this project works best if we get ~200-300 images of things that people think is broken. To expand our field, we can also include broken signs, labels, and other “minor” issues. <p>	Crowdflower workers will be incentivized to participate with a monetary payment.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: 	People who send in pictures will need the ability to judge if something is broken or not. They would only need the ability to keep their eyes out for broken items and identify them as such if they come across them. The Crowdflower workers would simply need to classify items based on how broken they appear to be.<p>
  how_will_you_ensure_the_quality_of_the_crowd_provides: 	The pictures that are being sent in are hard to verify unless we did it by hand, which can be possible if it’s limited to a set of 200-300 pictures. Crowdflower worker quality can be tested with an initial quiz that shows their relative accuracy.<p>
  how_will_you_aggregate_the_results_from_the_crowd: 	We can use a simple API such as Twilio to allow people to text pictures to a phone number. The Crowdflower results can simply be aggregated into a spreadsheet and CSV file that we can download and compares the crowd answers to our labels.<p>
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: 	First, we have to gather a set of 50-100 images, either from the Internet of from buildings around Penn, of items that are broken and visibly need fixing and items that look fine, and we would classify themselves by hand. We would put this set up on Crowdflower and ask them to classify the images into “definitely needs fixing”, “might need fixing”, or “looks fine”. We’d then take the labels that Crowdflower gave us and compare them to our hand-given labels to verify that the crowd and our team have the same general definition of “broken”. <p>      Next, we would try building our own classifier with a large corpus of images based on the features that we observed to be important in our initial phase. Ideally, we’d want to deconstruct the image into certain vectors that can help indicate a broken item, like uneven lighting or uneven structure in the image. If that has limited success, we can still try and classify the images as broken or not based on their location or even by the person who sent the picture in, among other associated metadata. <p>	Finally, we’d put these set of images on Crowdflower again and compare our classifier’s performance with the actual labels the crowd workers give us. We could put our entire dataset up to get all statistics on precision and recall, or just put the images that our classifier selected as “definitely needs fixing”.
  how_will_you_evaluate_if_your_project_is_successful: 	Using a standard statistics like precision and recall. Also, we can try and find the average distance between the label vector and the crowd workers vector (the lower “distance”, the better). <p>
  what_potential_problems_do_you_foresee_when_implementing_your_project: 	The biggest issue will be actually getting a critical mass of images for which to perform statistically significant machine learning on. One possible workaround is to extend the scope of the pictures to beyond just Penn’s campus, but that poses obvious problems with data sanity and standardization. I don’t think it’s infeasible to get the quick set of 50-100 images just to do an initial test for validation purposes. If we have a hard time just getting 50 images, then we may need to change our approach. Another big issue involves items that are broken internally, but that are not visible to the naked eye. We would try to discourage users from taking pictures of such items at the beginning, and maybe introduce them later once we have a solid model for visually broken items.<p>
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108286227
  name_of_your_project: EbolAware
  give_a_one_sentence_description_of_your_project: EbolAware determines how people are reacting to Ebola by analyzing data from social media.
  what_problem_does_it_solve: It solves the problem that we don't know how people react to things that are outside of their control and that don't immediately affect them. Ebola is a perfect case of this for most people. It is an epidemic happening on a different continent, yet it is a constant topic of discussion here in North America and on news outlets daily. Someone in the UN said that Ebola could be contained in 6 to 9 months but only if a massive global response was implemented. The start of a large scale global response is rooted in each individual's response to the crisis, and that is what I want to figure out more about. 
  what_similar_projects_exist: None that I know of, except polls on news websites about it. 
  what_type_of_project_is_it: social science experiment with social media
  who_will_be_the_members_of_your_crowd: The workers on crowdflower.
  how_will_you_incentivize_them_to_participate: Monetarily.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: They will provide a rating of the different emotions of the tweet that they are working on and the intensity of the emotion. For this they just need a working knowledge of English. 
  how_will_you_ensure_the_quality_of_the_crowd_provides: I will have multiple people working on the same tweet in order to verify the results, and I will have sample tweets that I work on to compare to the answers of the workers.
  how_will_you_aggregate_the_results_from_the_crowd: I will average all the data and then find the top ten sentiments about Ebola and rank them in order of average intensity. 
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: The first step is to crawl Twitter for tweets about Ebola, this will be done by me. The next step is to create a Crowdflower survey that takes several tweets, including a test one that I already know the general answer to, and gives it to a worker to gage the emotions and level of intensity of those emotions in the tweets. The last step is to aggregate and analyze the data, which I will do.
  how_will_you_evaluate_if_your_project_is_successful: I will consider this successful if by the end I have a result where there are recurring themes in people's tweets about Ebola, that the crowdworkers have noticed.
  what_potential_problems_do_you_foresee_when_implementing_your_project: Judging the level of intensity of emotion within a tweet is very subjective, so I think having a consistent way for the workers to judge the tweets will be the most difficult problem to solve. Another problem might be that there are such wide ranges of emotions and intensity levels that there are no clear sentiments towards Ebola on Twitter.
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108288606
  name_of_your_project: What Should I Cook?
  give_a_one_sentence_description_of_your_project: This app attempts to solve the problems of all those people who have ever wondered, What should I cook? given a full fridge and no recipes.
  what_problem_does_it_solve: Matching available ingredients for cooking to recipes made with those ingredients
  what_similar_projects_exist: Supercook, as far as I know, does this without the image recognition part
  what_type_of_project_is_it: Human computation algorithm, A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: Anyone who can recognize food images
  how_will_you_incentivize_them_to_participate: Tasks that pay for typing in names of food recognized in images, much like the receipt tasks that dominate MT.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: They provide training parameters for the OpenCV learner, no skills required
  how_will_you_ensure_the_quality_of_the_crowd_provides: Test questions would be used
  how_will_you_aggregate_the_results_from_the_crowd: The plan involves using the MT or CF APIs to automate machine learning for the image recognition, aggregates would be the end result of each task batch.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: Crowd&#58; responsible for looking at an image of food items and listing the items that are in the images (i.e. tomato, egg, watermelon, etc.)<p>Automated&#58; learn on sets of images to identify discrete foods, call the crowdsourcing API, download images from users, call BigOven API to look up recipes.
  how_will_you_evaluate_if_your_project_is_successful: If the image recognition can effectively give back more than 50% of the discrete ingredients from a picture of the inside of a stocked refrigerator, I would call the project a success.<p>On a more qualitative note, the project would be successful if the data flow from image upload -> classifier -> recipe worked.
  what_potential_problems_do_you_foresee_when_implementing_your_project: OpenCV is difficult to work with, the time it would take to train a classifier for image recognition is non-trivial, and especially parsing out discrete food items from an image of an open fridge seems to be a very complex problem.<p>Crowdsourcing problems include faking data, not agreeing with the classifier, and costs.
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108288605
  name_of_your_project: DesignMind
  give_a_one_sentence_description_of_your_project: DesignMind attempts to crowdsource voting on company logos, giving users the feedback that they want on a logo's effectiveness without all that focus group testing.
  what_problem_does_it_solve: Currently, brands find it difficult to know what makes a good logo and resort to lots of focus groups and A/B testing.  This is expensive and inefficient when crowdsourcing exists and the opinions of many can be decided very quickly.
  what_similar_projects_exist: 99designs.com crowdsources logo designs from designers and then lets brands pick from the end results, this would be somewhat the opposite of that but in the same vein.
  what_type_of_project_is_it: Human computation algorithm, A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: Anyone
  how_will_you_incentivize_them_to_participate: Pay-per-vote task, looking at each logo image and deciding which one is best for a particular case.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: They will provide all of the aggregate data that is returned to the user; basically, DesignMind attempts to be a gateway for companies to reach many people at once and get their thoughts and opinions.  They won't need any skills, since anyone could be a potential customer.
  how_will_you_ensure_the_quality_of_the_crowd_provides: One of the reach goals might be to implement worker filtering, so that some companies could target their desired audience for votes.  Otherwise, the quality of the crowd shouldn't be a problem since the only data needed is the vote.
  how_will_you_aggregate_the_results_from_the_crowd: Using the MT or CF APIs to gather the information and then present that back to the brand.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: Crowd&#58; responsible for voting on logo designs, choosing which one is better<p>Automated&#58; uploading design images, sending tasks out to workers, aggregating results, displaying results to brands, targeting different audiences.
  how_will_you_evaluate_if_your_project_is_successful: The project will be successful if the flow from app to task back to app works as expected and is quick enough for a potential customer to get feedback in a short amount of time.  Also, the success will depend on how expensive it ends up being to get a good chunk of aggregated data, versus the classic focus group cost.
  what_potential_problems_do_you_foresee_when_implementing_your_project: One problem could be that after pushing out the logo vote task, it takes too long to return any results.  Another would be the cost of the task itself, and yet another is the fact that brands still have to come up with their own logos in the first place in order to upload them.
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108296263
  name_of_your_project: Campus Cribs
  give_a_one_sentence_description_of_your_project: Market for Finding and Trading off-campus houses on campus.
  what_problem_does_it_solve: Every year, a new class of rising juniors seeks off-campus housing. The outgoing seniors can either pass their lease down to a group of their choosing or let the realtors decide who gets the house. In addition, the rising seniors often opt to look for a different off-campus house that will better suit their needs the following year. Right now, all of these people either have to know someone who's house will be up for lease or have to go to one of the campus realtors to find options.
  what_similar_projects_exist: Currently, Rental companies exist which pair buyers and sellers of houses, as well as renters and landlords. However, as far as we know, there is no service that helps students see all of their off-campus options in one place.
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: Penn undergraduates and graduate students.
  how_will_you_incentivize_them_to_participate: The algorithm will be individually rational, meaning that the users are guaranteed to exit the process with a house that either meets or exceeds the house that they go into the process with. If they don't find a better one, they keep their own. The program will collect features of their house and their preferences for a new one. It will match users for hand-offs and even for trades.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: They will need access to the internet and a upenn.edu email address.
  how_will_you_ensure_the_quality_of_the_crowd_provides: The users will have no incentive to lie about what their house offers because if they do and find a potential trade, the other party will quickly realize the falseness of the first party's offering and the first party will not get the trade they wanted.
  how_will_you_aggregate_the_results_from_the_crowd: We will allow users to sign up for the service and create a profile for bother their own house and the housing options they seek.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: First, users sign up and create personal preference profiles and profiles of their current house, including location, amenities, bedrooms, bathrooms, prices, condition, etc. They are then entered into a pool of other options on campus. If a match between their preferences and another house occurs, the two parties are connected automatically. If a potential three or more way trade occurs, the trade will be suggested to all of the parties automatically. If the trade is accepted, the users can take their houses off the market. We can collect data about offers and then sell that data to the landlords. This will be useful information for them about the demand for each of their properties, and will allow them to rethink pricing to match that demand.
  how_will_you_evaluate_if_your_project_is_successful: We will collect data surrounding how often matches are made and how often those trades are accepted.
  what_potential_problems_do_you_foresee_when_implementing_your_project: Consumer adoption may be a problem, especially because by the time we finish implementing the platform a lot of the properties will be signed for next year.
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108296933
  name_of_your_project: ShopForMe
  give_a_one_sentence_description_of_your_project: ShopForMe attempts to use the opinions of thousands of crowdsourced users to act as a personal style consultant, judging articles of clothing for users to buy.
  what_problem_does_it_solve: Most people dress in order to look good to other people.  Why not get thousands of opinions from those very people instead of only relying on yours and maybe one other person's? We can use crowdsourced results to decide which clothes to buy among multiple articles of clothing and multiple sets of clothing.
  what_similar_projects_exist: Sew Love is a Kickstarter project that crowdsources clothing designs, which is similar to this project, except that this one takes existing designs and has crowds vote on them.
  what_type_of_project_is_it: Human computation algorithm, A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: Anyone
  how_will_you_incentivize_them_to_participate: Pay per vote, tasks that involve looking at different clothes and picking which one is best.  Paying for the opinions of others.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: The workers will provide their own opinions on what styles look best and aggregating the collected data provides the app with its final judgment on which article of clothing to buy.
  how_will_you_ensure_the_quality_of_the_crowd_provides: Since the question is only asking for their opinion, unless the crowd purposefully lies about what they think, there should be no problem.  The quality of the data is averaged out over many judgments.
  how_will_you_aggregate_the_results_from_the_crowd: All of the results for a given set of pictures/clothes will be aggregated into one final result.  The original user will then receive the result judgments and have a better sense of what to buy.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: Crowd&#58; responsible for looking and comparing urls that hold clothing items.  The task would be to judge which item they liked more.<p>Automated&#58; sending tasks out to workers, ingesting urls from users, giving users the final feedback, aggregating data, visualizing data in a useful manner.
  how_will_you_evaluate_if_your_project_is_successful: If the project is successful, the final decision returned by the crowdsourced task should roughly equate to that of the majority opinion when asking people.  The result should also not take very long to return, and the task shouldn't cost much.  The cost of the task will be the most limiting part, since a thousand judgments is on the order of tens of dollars, which is unsustainable.
  what_potential_problems_do_you_foresee_when_implementing_your_project: Cost, as described above.<p>Difficult to separate clothing into different types of articles, thus making it different to compare a sweater to a scarf.
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108298344
  name_of_your_project: ParkYeah
  give_a_one_sentence_description_of_your_project: ParkYeah is a mobile application that aggregates the GPS data of people looking for parking in order to provide users with areas where they will have the best chance of finding street parking.
  what_problem_does_it_solve: Finding street parking is typically a very frustrating task, especially in in a big city - daily/weekly/yearly parking patterns can be very difficult to guess and can affect a driver's willingness to make a trip to begin with.  This app will use gps data from people looking to find parking in order to estimate the probability of finding parking in certain areas.  Other users can use this information to make informed decisions about where to look for parking to make their search shorter and less frustrating.  
  what_similar_projects_exist: There are a number of other park-assisting apps (many which are city-specific) but these often only geared towards metered spots or garages.  None use the wisdom of crowds. 
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: Any urban residents looking for street parking
  how_will_you_incentivize_them_to_participate: Using the app will help users save, time, money and gas while looking for parking.  Therefore they will have an incentive to use the app and provide their own GPS data.  
  what_will_they_provide_and_what_sort_of_skills_do_they_need: They simply provide their GPS data while they look for parking.  An internal machine learning algorithm then uses this data to compute the probability of finding parking in each area (e.g. city block) for all users based on the searching patterns of people using the app. 
  how_will_you_ensure_the_quality_of_the_crowd_provides: Users will only be giving their GPS data, and therefore cannot lie.  The probably estimates made via machine learning can be cross-checked by having crowdworkers identify the parking congestion levels of certain areas by looking at satellite images.  This will be used to make sure the machine learning classifier is accurate.  
  how_will_you_aggregate_the_results_from_the_crowd: GPS data points from the crowd will be fed into a machine learning algorithm (see above) that outputs a parking-probability map of the area.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: Crowds download the mobile app and open it on their phones.  This simultaneously shows the user a parking-probability map of the area that they are in while taking in a stream of GPS data points form the user currently looking for parking in order to make the map more accurate.  People looking for parking rely on other peoples data and vise versa, so the process is somewhat cyclical&#58;<p>- user is shown computed probability map<p>- GPS stream is sent to central server<p>- algorithm updates probability map given new data points<p>- updated map is refreshed on mobile app   
  how_will_you_evaluate_if_your_project_is_successful: ParkYeah will be successful if many users rely on it for parking information - this will be an indication that it saves people time and money.
  what_potential_problems_do_you_foresee_when_implementing_your_project: The machine learning aspect will likely be difficult to make accurate.  It will be important to guess information like when exactly and where a user ultimately finds parking, and use this to accurately guess how congested the area must be.   
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108300456
  name_of_your_project: PennCrowd
  give_a_one_sentence_description_of_your_project: This app will let students know how crowded different campus spots are.
  what_problem_does_it_solve: Students often go to a place on campus only to find that it is too crowded for them to be productive. Whether its the gym, a dining hall or a study building, this can be a huge pain in the neck. The app will help students decide whether or not to start venturing toward some hot spot, and potentially find alternatives.
  what_similar_projects_exist: Foursquare is a similar platform, but it is not specific (or useful) to campus. Wharton also shows you how many GSRs are booked at one time, but it does not show you how crowded other parts of the building are.
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: Penn Students
  how_will_you_incentivize_them_to_participate: Students will participate automatically, without changing their behaviors. We plan to utilize a PennCard API to determine how many students check into different spots on campus, and at what times. Checking in by swiping a PennCard is something students do already.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: They do not need any specific skills and will provide real time information about how many people are in each location.
  how_will_you_ensure_the_quality_of_the_crowd_provides: We will ask students to rate the accuracy of the app's prediction once they arrive at a spot. We will use this, along with checkins and timestamp data to optimize the machine learning algorithm.
  how_will_you_aggregate_the_results_from_the_crowd: We will collect data from the PennCard API.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: A student walks into Huntsman at night (or any other campus location that requires a swipe) and swipes in with their PennCard. Other students can then open the app and check how crowded the area is based on how many other students have recently checked in.
  how_will_you_evaluate_if_your_project_is_successful: We will collect feedback in the app and will also collect data on how often students are using it, and whether or not they continue to use it after using it a few times.
  what_potential_problems_do_you_foresee_when_implementing_your_project: There may not be a useful PennCard API or the University may not allow us to use the information regarding individuals' whereabouts.
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108317872
  name_of_your_project: MarketChatter
  give_a_one_sentence_description_of_your_project: MarketChatter allows an analysis of the stock sentiment by examining data from social media and news articles.
  what_problem_does_it_solve: Investors frequently want to know how lay people perceive a company. Spotting upticks in volume in the number of times a company is referenced in the media allows people to monetize momentum as well as gauge retail interest in companies. This also allows investors to recognize bad news even before a company press release if a lot of consumers rant about the product on social media platforms<p>
  what_similar_projects_exist: StockTwits is a financial communications platform that makes analyzes sentiment by looking at twitter feeds.<p>Bloomberg incorporated real time twitter information into its terminals through the TWTR<GO> command.<p>StockPulse makes use of MIT research on stock sentiment analysis as a basis for its business model.
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: The crowd will primarily consist of customers who are talking about their experience with products on social networks. The crowd also includes journalists posting news articles about a company.  
  how_will_you_incentivize_them_to_participate: Customers inherently like talking about any extreme negative or extreme positive experiences with any particular firms. Social media allows them to rant about their experiences. Talking about their experiences also helps them feel as though they are helping out friends in their network to avoid bad opportunities and pursue good opportunities. On the other hand, journalists are naturally incentivized in producing content that generates a lot views since that affects their standing in the media industry. <p>
  what_will_they_provide_and_what_sort_of_skills_do_they_need: The customers are essentially providing reviews on a voluntary service. The nature of the project implementation means that it only includes customers that can interact on social medial. Journalists just need a website to post their content. The project will scrape articles from across the web that reference a particular company. <p>
  how_will_you_ensure_the_quality_of_the_crowd_provides: A quick check for QC is whether that consume or journalist has ever posted content on social media or the web in the past. If this is the first post, then it could simply be a fake user. Another check is whether the user has posted multiple times across different social networks in which case the user is is simply trying to increase his own personal influence. <p>
  how_will_you_aggregate_the_results_from_the_crowd: The project will scrape information from twitter and across other social media and news sites. This aggregation will provide the data necessary for the sentiment analysis. <p>
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: Customers voluntarily post information about their experiences online. Journalist post news stories about companies online. Both of these steps are done by the crowd. The program would scrape the web for data about a particular company. This is done automatically. The data points are pushed back to a crowdsourcing platform to have a crowd of workers assess the sentiment as positive, neutral, or negative.<p>
  how_will_you_evaluate_if_your_project_is_successful: The project evaluation will consist of taking a ticker or company name as input and seeing whether a report that summarizes the sentiment for the company currently is generated. <p>
  what_potential_problems_do_you_foresee_when_implementing_your_project: When scraping for data, it is important to isolate data that is current; in other words, remove stale data from a long time ago that is still posted on the web. This project only gives a snapshot of sentiment. It maybe helpful to see sentiment for a particular stock temporally. <p>
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108317906
  name_of_your_project: CrowdCheck
  give_a_one_sentence_description_of_your_project: CrowdCheck is a tool that utilizes crowdsourcing to pre-parse and check for overly intrusive terms of service agreements, particularly in the area of privacy policies.
  what_problem_does_it_solve: In today’s digital world, the distribution of personal data is a primary concern for users of popular websites. However, even the privacy-conscious often do not take the time to sift through the excessively long agreements that must be accepted prior to using most software applications and websites.
  what_similar_projects_exist: There is a project called Terms of Service; Didn’t Read that has very similar goals, but this project has struggled to obtain “enough data to make solid comparisons yet” and can not even be used to for popular services such as Facebook.
  what_type_of_project_is_it: Human computation algorithm
  who_will_be_the_members_of_your_crowd: The workers on Mechanical Turk are the members of our crowd.
  how_will_you_incentivize_them_to_participate: We will use monetary incentives that potentially increase for a recurring user as he/she builds a successful track record over time.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: The crowd members will assist in categorizing privacy policies into different levels of intrusiveness. This will require basic skills such as reading comprehension and preferably a familiarity with legal terms.
  how_will_you_ensure_the_quality_of_the_crowd_provides: The primary method of quality control is via monetary incentives, as a contributor will only be exposed to increased earnings if their previous categorizations were found to be correct. Additionally, a pre-test will be implemented to ensure that contributors have a basic understanding of the legal terms often found in these agreements. Finally, the users of the tool can optionally provide feedback on the recommendations the tool provides.
  how_will_you_aggregate_the_results_from_the_crowd: This project will aggregate results directly from contributors as they complete the tasks on Mechanical Turk.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: The first step will be to scrape the privacy policies of various websites and split them into small chunks, such as paragraphs, in an automated process. Next, crowdsourced workers will apply labels to paragraphs of privacy policies such as ‘Tracks you on other websites’. Finally, an automated process will aggregate the data collected from contributors to assign overall ratings to websites.
  how_will_you_evaluate_if_your_project_is_successful: Feedback from users will help indicate how accurate the ratings are. Additionally, if the tool gathers enough support, companies being categorized will be incentivized to notify us of false negative categorizations. At a more general level, the goal is not only to aid users but to also incentivize companies to provide fair policies. Thus, one way to measure success would be to consistently check websites for updated policies that may be in response to categorizations presented by this tool.
  what_potential_problems_do_you_foresee_when_implementing_your_project: The primary problem in implementing this project will be to determine a standardized set of labels for crowdsourced contributors to flag as ‘present’ or ‘not present’. Generating this set of labels could be a crowdsourced task of its own.
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108317905
  name_of_your_project: DealFlow
  give_a_one_sentence_description_of_your_project: DealFlow essentially serves as as a platform for idea generation for Venture Capital firms by crowdsourcing the sourcing aspect of a VC analyst’s job. 
  what_problem_does_it_solve: A large part of VC analyst’s job consists of calling companies and creating lists of companies available for sale that meet a particular sector/theme requirement. By the nature of type of investing employed by VC firms, the opportunity set primarily consists of private companies. <p>After VC firms find a big picture secular technology theme they want to invest in, they need to compile a list of companies in that space. This is a difficult task since the targets are mostly small, private companies. 
  what_similar_projects_exist: Financial databases like CapitalIQ provide some information on private companies, but it doesn’t fulfill the aspect of a VC’s job such as contacting companies and seeing if they are available as prospective investments.<p>PitchBook provides lists of companies that are already VC or PE backed and doesn’t effectively list prospective VC opportunities.
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: The crowd will consist of entrepreneurs and business people. These people have social clout. They all have experiences with different types of business models and various sectors. 
  how_will_you_incentivize_them_to_participate: Members will be partially compensated by the volume of unique businesses they can list that meet a particular theme for investing i.e. cloud computing for education. Members will primarily receive compensation through an incentive fee if a deal listed by them on the platform eventually generates a successful lead for a VC firm. This incentive fee can serve as a pseudo transaction fee for a PE firm. <p>
  what_will_they_provide_and_what_sort_of_skills_do_they_need: The crowd would need to have knowledge of smaller, private businesses. The crowd also needs to have an extensive network of business contacts to create a more meaningful list of prospective targets. This means that the members of the crowd can generate proprietary deal flow, which is the holy grail of VC investing.<p>
  how_will_you_ensure_the_quality_of_the_crowd_provides: The crowd quality will be assessed by a check of whether the businesses provided in the list actually exist. The company can be cross referenced with publicly listed companies to ensure it is private. The website that is listed along with each respective company can be evaluated to see if it contains the tag words for the investment theme being evaluated. <p>
  how_will_you_aggregate_the_results_from_the_crowd: The aggregation will essentially take place over a website where businesses idea lists will get uploaded by the crowd under a respective investment theme. <p>
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: The website will provide an exhaustive, updating list of investment themes that are interesting for VCs. The crowd will create lists of businesses that meet the various themes. The quality control described earlier will be done automatically.<p>
  how_will_you_evaluate_if_your_project_is_successful: The evaluation of the project will be determined by whether quality lists can be generated for different investment themes. <p>
  what_potential_problems_do_you_foresee_when_implementing_your_project: The main problem will be getting the target crowd to be aware of the the product. Since this will be a new model for investing, both the crowd and VC firms may have initial skepticism. <p>
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108321191
  name_of_your_project: WikiTrend
  give_a_one_sentence_description_of_your_project: News trend prediction through wikitopics
  what_problem_does_it_solve: There is burst of news everyday. There are some major trends, however, underlying those news but  are not clearly revealed. With increase personalization on the Internet today, it’s harder for us to catch up with the real trending topics. 
  what_similar_projects_exist: There is a research paper (provided on course website) about using natural language processing in finding the trending topics through wiki data, but they didn’t include human computation into the algorithm, which can be a crucial part in defining the importance of certain news piece, or whether the results make sense. 
  what_type_of_project_is_it: Human computation algorithm, Social science experiment with the crowd
  who_will_be_the_members_of_your_crowd: CrowdFlower or Amazon MechanicalTurk
  how_will_you_incentivize_them_to_participate: Due to the nature of those platforms, we plan to use money to incentivize them. 
  what_will_they_provide_and_what_sort_of_skills_do_they_need: They identify whether some news trends make sense or whether they match some ongoing hot events. They need to be able to read and have a basic cultural background, preferably US residents considering the source of our news/wiki data. 
  how_will_you_ensure_the_quality_of_the_crowd_provides: We will use iterations to ensure the quality. Basically we hope that the crowd can provide the training data for algorithm. The algorithm in return will generate better tasks for the crowd. 
  how_will_you_aggregate_the_results_from_the_crowd: I don’t have a clear idea on the forms of tasks yet. I plan to ask the crowd match key words with news articles or extract key words from news articles. For this task I can create an algorithm to filter the results and find common ones. I might also ask the crow to write summaries of my generated results. For this task I would probably use iterations. 
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: I don’t have a clear idea yet. I need to do more research before designing the tasks. 
  how_will_you_evaluate_if_your_project_is_successful: I can create a brief summary of some news trends and also generated some data or web links to support my results. 
  what_potential_problems_do_you_foresee_when_implementing_your_project: The clustering algorithm can be hard to implement. It’s also hard to envision how to best use crowds to provide useful training data for our algorithm. 
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108326857
  name_of_your_project: FowlCmdy
  give_a_one_sentence_description_of_your_project: FowlCmdy rates/filters funny pages on Twitter. 
  what_problem_does_it_solve: Twitter has a large amount of humorous content (comedy pages/parody accounts/etc). It can be difficult to filter all this content and find the true gems. 
  what_similar_projects_exist: There are no similar projects. However, the comedy pages that will be ranked typically aggregate material from many sources. 
  what_type_of_project_is_it: Human computation algorithm
  who_will_be_the_members_of_your_crowd: Crowdflower workers 
  how_will_you_incentivize_them_to_participate: Money will be paid to people who give responses. 
  what_will_they_provide_and_what_sort_of_skills_do_they_need: They will provide their opinion(whether a tweet is funny or not) and need no expertise. 
  how_will_you_ensure_the_quality_of_the_crowd_provides: We will predetermine tweets that are not related to humor and add them to each survey. People that respond favorably to those tweets will not be taken into account/paid. 
  how_will_you_aggregate_the_results_from_the_crowd: We will use Crowdflower's aggregation tools. 
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: 1. Collect tweets <p>2. Filter for funny tweets <p>3. Collect data from Crowdflower <p>4. Use algorithm to rank pages <p>
  how_will_you_evaluate_if_your_project_is_successful: We will check out the top ranked pages and hopefully find some funny material. 
  what_potential_problems_do_you_foresee_when_implementing_your_project: It may be difficult to filter out funny tweets. Also, figuring out how to get equal representation from many pages will be a challenge. Finally, comedy is subjective and the crowd may not agree on what is funny.
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108329235
  name_of_your_project: Ant Sirs
  give_a_one_sentence_description_of_your_project: Ant Sirs helps students with homework. 
  what_problem_does_it_solve: People get stuck on difficult homework problems.
  what_similar_projects_exist: Stack overflow attempts to solve similar problems, but it is more focused on computer programming. Student of Fortune also solves a similar problem, however with only tutors answering questions. 
  what_type_of_project_is_it: Human computation algorithm
  who_will_be_the_members_of_your_crowd: Crowdflower workers
  how_will_you_incentivize_them_to_participate: Money provided by the person looking for help with homework. 
  what_will_they_provide_and_what_sort_of_skills_do_they_need: They will provide anything that will help solve the homework problem/make it easier. Also, vote on any new additions to the answer. 
  how_will_you_ensure_the_quality_of_the_crowd_provides: Voting on each new addition. 
  how_will_you_aggregate_the_results_from_the_crowd: If positive votes are sufficient, additions are incorporated into final result. 
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: 1. HW Prob posted <p>2. Workers make additions/vote on previous additions by other workers <p>3. Final Answer/Help is condensed 
  how_will_you_evaluate_if_your_project_is_successful: Reviews by people that post questions. Good answer/fast process. 
  what_potential_problems_do_you_foresee_when_implementing_your_project: Legal issues(we want to help, not help people cheat). Voting system may be hard to keep track of, also may not work. 
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108331180
  name_of_your_project: RapGenii
  give_a_one_sentence_description_of_your_project: Crowdsource creation of rap lyrics about a topic
  what_problem_does_it_solve: The problem of not having hilarious rap lyrics about random topics
  what_similar_projects_exist: Rap Genius (http://rap.genius.com/) does analysis of rap lyrics, but does perform rap lyric generation<p>Rap Pad (http://rappad.co/) allows aspiring rappers to create their own lyrics and share with others<p>
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: Bored internet denizens
  how_will_you_incentivize_them_to_participate: Give them “rap god points” based on the amount of proposed lyrics get accepted
  what_will_they_provide_and_what_sort_of_skills_do_they_need: The crowd will provide lyrics about a topic. They will see what has been generated for the poem so far, and will be asked to add a line onto the poem. We hope to provide a list of related words that go along with the topic, to aid in lyrics generation. Additionally, voters will compare suggested lyric lines and choose which one they find preferable. 
  how_will_you_ensure_the_quality_of_the_crowd_provides: We will get other users to rate rap lyrics, possibly by getting them to vote between two possibilities.<p>
  how_will_you_aggregate_the_results_from_the_crowd: The poem will be aggregated naturally as we decide which line to add on to the poem at each step.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: The process will have two steps&#58; rap lyrics generation and lyrics rating. Both steps will be done by the crowd, as these are not tasks which can be easily performed by computer.<p>Rap lyric generation&#58; The user will see what has been generated for the poem up to this point, and will know the theme of the poem. Additionally, we hope to find a consistent way of providing related words for the user to include in their lyrics.<p>Rap lyric rating&#58; A user will look through two possible lines (neither of which may be the one that they suggested) and vote for the one they prefered. Using this method, we can create a ranking of the possible lyrics and choose the most popular line.<p>
  how_will_you_evaluate_if_your_project_is_successful: We will define success partially out of our own personal enjoyment of the lyrics produced, and we can also rate the lyrics more objectively by asking the crowd to either upvote/downvote raps or to generally provide a rating of raps. Using this, we will be able to verify whether alterations of our system affect rap production quality for the better or worse.
  what_potential_problems_do_you_foresee_when_implementing_your_project: The users could be lazy and not give particularly creative lyrics. Also, a sparsity of users will make rap generation and lyrics rating difficult and of sub-par quality.
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108331153
  name_of_your_project: Crow de Mail
  give_a_one_sentence_description_of_your_project:  Crow de Mail writes emails for you in any context. 
  what_problem_does_it_solve: Writing emails can be difficult. People must consider tone, wording, and other conventions, which is especially difficult if English is not your first language. 
  what_similar_projects_exist: No similar projects exist.
  what_type_of_project_is_it: Human computation algorithm
  who_will_be_the_members_of_your_crowd: CrowdFlower workers
  how_will_you_incentivize_them_to_participate: They will be paid for their work.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: They will provide proper wording for the email based on context given to them by the requester. They would need knowledge of spelling, grammar,etc. 
  how_will_you_ensure_the_quality_of_the_crowd_provides: Voting by other workers will provide quality. 
  how_will_you_aggregate_the_results_from_the_crowd: Emails/edits with low voting scores will be dropped. The highest few will be sent to the requester. 
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: 1) Email request posted with context <p>2) Workers edit/vote/post answers <p>3) Top Final Versions returned 
  how_will_you_evaluate_if_your_project_is_successful: Relatively quick responses with emails that match a variety of situations. 
  what_potential_problems_do_you_foresee_when_implementing_your_project: Aggregating info may be difficult. Also how much would the cost be? <p>
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108337645
  name_of_your_project: Rent-a-Kitchen
  give_a_one_sentence_description_of_your_project: Application that allows student users to rent kitchens from peers in exchange for food or money.
  what_problem_does_it_solve: Many students who live in dorms without kitchens suffer from the low quality of accessible food.<p>
  what_similar_projects_exist: The Culinary Studio allows customers to rent kitchens within a community. Kitchen Share allows customers to rent kitchen utensils.<p>
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: Penn Students
  how_will_you_incentivize_them_to_participate: On the one hand, the students looking to use the kitchen will be incentivized by the prospect of using a kitchen. On the other hand, the students looking to rent out their kitchens will be incentivized by either the money or the food.<p>
  what_will_they_provide_and_what_sort_of_skills_do_they_need: The kitchen providers will provide their kitchen real estate. Kitchen equipment is provided at the provider’s discretion. The kitchen seekers will provide either money or freshly prepared food. In the case of the freshly prepared grub, the seekers will need culinary skills.<p>
  how_will_you_ensure_the_quality_of_the_crowd_provides: A rating and feedback system for both kitchen providers and kitchen seekers will be used. The ratings will be made available to all parties so seekers can choose providers they are satisfied with and providers can accept only seekers they have faith in. If the seeker is not satisfied with the state of the provider’s kitchen upon arrival, he/she will not have to pay in food or money (providers of the kitchens will be audited before they are allowed to rent out their space so that no sketchy locales fall through the crack). The food quality of the food prepared by the seekers will be FDA approved. 
  how_will_you_aggregate_the_results_from_the_crowd: The results from the crowd will be aggregated in an application (either mobile or web). A user seeking to rent a kitchen will be able to use the application to search for users who are willing to provide kitchens. Additionally, kitchen providers will be able to use the application to connect with kitchen seekers and obtain food or money in return.<p>
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: Everyone willing to rent out their kitchens will post the times and location of their kitchen availability. Kitchen providers will include any restrictions enforced in their kitchen, such as food allergies or dietary restrictions. They will also indicate whether they want to be paid in cash money or in fresh grub. Kitchen seekers will search on the site/app when they want to use a kitchen, and our state-of-the-art pairing program will give them suggestions on nearby kitchens that match their timeslot. Kitchen seekers can then send a request to a kitchen provider, who can approve or reject the request based on the seeker’s reputation (evaluated through ratings). If approved, the seeker and provider coordinate any sharing between kitchen equipment and ingredients.  After the seeker has completed, both seeker and provider rate each other.
  how_will_you_evaluate_if_your_project_is_successful: We will evaluate our project by getting a few users (both kitchen seekers and kitchen providers) to try our application. We would then ask the users to fill out a survey about their experience using the application. The survey would include such questions as “Rate your overall experience using the application,” “Would you be interested in using this application in the future,” etc. The feedback from this survey would be the primary method we would use to determine the success of the project.
  what_potential_problems_do_you_foresee_when_implementing_your_project: There are safety and privacy concerns. Kitchen owners will be allowing strangers come cook in their dorm. Users could steal from the home, accidently start a fire, spill milk on the floor, etc. On the user end, students may feel awkward cooking in random people’s homes.<p>
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108344234
  name_of_your_project: Identifying Geographical Biases in Gender Roles (sorry it's boring...but I thought it made sense given the topic!)
  give_a_one_sentence_description_of_your_project: Use surveying people’s preferences and interest to guess their gender in a study to figure out how gender roles play out in different geographical locations.
  what_problem_does_it_solve: Helping to develop a better understanding of how gender roles are defined by society (our interests and preferences) and how these things differ throughout the world. We can better understand nature vs nurture in terms of how we identify.<p>
  what_similar_projects_exist: Hunch used to do something similar, except instead of gender, it would guess things like political views.
  what_type_of_project_is_it: Social science experiment with the crowd
  who_will_be_the_members_of_your_crowd: A diverse group of people from all over the world - hopefully a strong combination of men, women and other-gender-identifying individuals, as well as a diversity of people from different locations and age groups.
  how_will_you_incentivize_them_to_participate: We will pay them via Crowdflower.<p>
  what_will_they_provide_and_what_sort_of_skills_do_they_need: They will answer several questions about themselves - do they like the city, do they prefer the outdoors, whether they enjoy cooking, what their dream life will be in several years etc. And then they will tell us how they identify (and if necessary, where they are from). They will likely need to know how to read English - though potentially we can translate.  <p>
  how_will_you_ensure_the_quality_of_the_crowd_provides: We will throw in a “dummy question” to make sure they are paying attention - for example, “what color is the grass&#58; green black grey white” and check for a real answer - for example, real text that has real English that makes sense every hundred or so questions.<p>
  how_will_you_aggregate_the_results_from_the_crowd: We will primarily use multiple choice question to gauge preferences, and potentially for the short answer questions - we will parse out certain verbs and nouns from a dictionary and put that in as interests - for example, “I  see myself as a construction worker” might get parsed as “construction” or “worker” and see if there are any strong correlations. <p>Alternatively, We can also do a separate Crowdflower task to verify the results and have Crowdworkers parse relevant verbs and nouns for us and then machine learn a small test set - and see if we can predict accurately. We will primarily use multiple choice question to gauge preferences, and potentially for the short answer questions - we will parse out certain verbs and nouns from a dictionary and put that in as interests - for example, “I  see myself as a construction worker” might get parsed as “construction” or “worker” and see if there are any strong correlations. <p>
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: We will put together a survey asking people to fill out their interests, preferences and life goals. We will put this on Crowdflower. We will collect hopefully around 10,000 responses or so.<p>From the data we collected, we will create a small data set of about 1,000 responses whose gender we have collected. We will create a unigram based on this for males and females and use this to build a classifier.<p>We will then run this on the rest our data and see if we can predict whether they are females or males based on the information we got from the survey.<p>We can then check this against the information they gave us (are they really male or female).<p>Then we can map correlations and geography in some sort of data visualization that represents how gender roles have defined interests and preferences across the world.<p>
  how_will_you_evaluate_if_your_project_is_successful: We can look at the final data - and see how accurate how classifier was at predicting gender and also from the visualization, we can see if there were any real strong correlations based on geographic location (for example, if some places have stronger preference-gender correlation, which would be really interesting).
  what_potential_problems_do_you_foresee_when_implementing_your_project: Not getting enough meaningful data, people not being as transparent as they could be during the survey, potentially people being lazy and not putting real answers. We could potentially combat this by releasing the visualization at the end and giving them a preview of what it would look like to increase interest in the project.<p>Resulting bias in answers if we indicate what the project is for.
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108343330
  name_of_your_project: Note My Time, Note My Problem
  give_a_one_sentence_description_of_your_project: Application that allows students to split up the note taking process and share lecture notes.
  what_problem_does_it_solve: For various reasons, students might like the option to not take notes during lecture. For example, some students learn better by focusing on listening to the lecture rather than frantically scribbling down notes. However, in many classes written notes prove essential when studying for a test. Our solution to this problem crowdsources notetaking to allow everyone to maximize their learning potential.
  what_similar_projects_exist: Course Hero allows users to buy study aid materials or hire tutors for classes. StudyBlue allows users to share notes and flashcards with other users. Koofers provides access to notes and old exams. GradeGuru provides a study platform where students can share and find class-specific study notes. The main difference between these companies and ours is that ours crowd sources the work in a unique manner, increasing the quality of the notes and guaranteeing the existence of notes for a given class. It is also free for anyone who contributes to the note taking process.
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: Students taking classes at Penn.
  how_will_you_incentivize_them_to_participate: The setup of the idea is self-incentivizing because each of the participants directly reaps the benefit of the work done. Each user gets access to the lecture notes that they contribute to. Therefore, they have incentive to participate because they can get access to all the lecture notes by only taking notes for a few time slots.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: They will provide notes on the class material. The skills required are your basic college note-taking skills (College 101 material).
  how_will_you_ensure_the_quality_of_the_crowd_provides: Participants note-taking ability will be rated by their peers. If someone is taking clearly subpar notes, his peers will rank him down. After a certain number of down-ranks, the participant will be kicked out of the group.
  how_will_you_aggregate_the_results_from_the_crowd: Each person’s notes will added to a Google Doc-esque document, which will provide for real-time aggregation of the notes taken.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: First, participants will enroll on our website for a class. Then, the students in each class are split into even size groups of maximum 20 people each. The groups will be assigned randomly and the names will be shared among the group to incentive students to take notes. Students in each group will sign up for 20 minute time slots, first-come-first-serve, for which they will be responsible for taking notes (e.g. 11&#58;00 - 11&#58;20). There will be two students taking notes in each time slot. During the class, each participant is free to listen, note-free and care-free, until it is his/her time to take notes. At the end of the class, each participant will upload his/her notes to a shared document and everyone in the group will have an entire lecture’s worth of notes for a fraction of the note-taking time. The note takers will be rated by other members of their group based on the quality of the notes. The users will not see these ratings; they will be used internally to warn and remove users that have consistently bad reviews. If a student misses his/her time slot without presenting an acceptable excuse from the rest of the group, he/she will be given a warning and if it is repeated, the person will be kicked out of the group.
  how_will_you_evaluate_if_your_project_is_successful: We will test our implementation with a test group and evaluate based on quality of produced notes.
  what_potential_problems_do_you_foresee_when_implementing_your_project: Although we will implement a rating system to rate participants who are slacking, there is always the worry of free-loaders who will join a group without contributing their fair share. Also, there is the issue of people spamming the Google Doc or other note-taking doc with irrelevant junk.
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108322309
  name_of_your_project: Food Flip
  give_a_one_sentence_description_of_your_project: Food Flip makes living with food restrictions easier by crowdworkers giving suggestions for recipe swaps.
  what_problem_does_it_solve: It's hard to find things to eat when you’re food-restricted and regular recipes don't cater towards your restrictions
  what_similar_projects_exist: These aren't crowdsourced projects - just static websites that give advice to deal and live with food restrictions&#58;<p>http://www.kidswithfoodallergies.org/resourcespre.php?id=93&<p>http://www.eatingwithfoodallergies.com<p>
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: People with experience cooking with food restrictions.
  how_will_you_incentivize_them_to_participate: For the sake of itself - to improve the quality of knowledge of food restricted cooking. One can also hone his cooking skills by getting feedback on likes and dislikes. Lastly, one can feel part of a the community by contributing.<p>
  what_will_they_provide_and_what_sort_of_skills_do_they_need: The crowd will provide ideas for recipe substitutions. They need experience with food restrictions and experience cooking (well).
  how_will_you_ensure_the_quality_of_the_crowd_provides: All website users can thumbs up/thumbs down substitution suggestions, similar to StackOverflow. The suggestion with the highest amount of thumbs-up will be displayed most prominently.
  how_will_you_aggregate_the_results_from_the_crowd: An non-spam submissions will be shown on the page of the question, similar to StackOverflow.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: User asks question,<p>Crowd submits an answer to the question,<p>Computer can learn common swaps and suggest swaps.
  how_will_you_evaluate_if_your_project_is_successful: If users are using the website and review that they are happy with the ideas suggested, the project can be deemed successful.
  what_potential_problems_do_you_foresee_when_implementing_your_project: Problematic is all the code involved with writing and running this website. 
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108322394
  name_of_your_project: Room Tetris
  give_a_one_sentence_description_of_your_project: A website that enables one to get personalized ideas on how to plan and layout a room.
  what_problem_does_it_solve: People with bad spatial abilities might not be able to determine the optimal configuration of items in a room, given the room layout and pieces of furniture. This website will allow people to ask the crowd what to do and where to put their furniture.
  what_similar_projects_exist: There are online tools to let people plan out their rooms, but no tools that utilize crowdsourcing&#58;<p>http://www.potterybarn.com/design-studio/tool/bedrooms_room_planner.html<p>http://www.floorplanner.com/projects/18885826-living-room-layout-help/floors/18959017-ground-floor/designs/20242632-living-room#details<p>http://www.bhg.com/rooms/living-room/room-arranging/<p>
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: People interested in design and have good spatial skills.
  how_will_you_incentivize_them_to_participate: Workers will be paid small somes of money for submitting good ideas. 
  what_will_they_provide_and_what_sort_of_skills_do_they_need: Workers are asked to submit their optimal arrangements of furniture in the given room. Workers need good spatial skills and possibly design skills.
  how_will_you_ensure_the_quality_of_the_crowd_provides: The customer can choose his favorite configuration and the selected user gets paid more money for his good answer. 
  how_will_you_aggregate_the_results_from_the_crowd: People pay to have rounds of answers - the customers chooses their favorite configuration and they “win” the contest and get paid.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: User submits the dimensions of their room and the dimension and types of all their furniture. <p>The computer generates a room image and lets crowdworkers rotate piece of furniture around in the room.<p>The crowd submits their optimal arrangement for the given room type<p>The user chooses their favorite arrangement and that person gets paid.<p>
  how_will_you_evaluate_if_your_project_is_successful: If the user is happy with the arrangement, for the money he/she put in.
  what_potential_problems_do_you_foresee_when_implementing_your_project: Problematic is all the code involved with writing and running this website. People might not submit responses in time to be useful to the user.
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108322810
  name_of_your_project: Eventor
  give_a_one_sentence_description_of_your_project: Crowdsource out event planning to those people who can fully plan the event for you.
  what_problem_does_it_solve: Any user has an event that needs planning, from small birthday surprise, to large-scale corporate events. The many small details of this event can be compiled from the many in the crowd, to get any event planned in significantly less time.<p>Solves&#58; lack of creativity<p>laziness<p>indecisiveness<p>inability to understand all of the perspectives<p>inability to be 10 people at once<p>time constraints <p>
  what_similar_projects_exist: https://www.planningpod.com/<p>Eventster is somewhat similar, in that it crowdsources a group of people about events, although it is mainly focused with people discovering new, already planned events in the area.<p>http://techcrunch.com/2012/06/08/eventster-brings-crowdsourced-event-discovery-to-iphone-ipad/
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: General Community as well as hospitality management students and professionals.
  how_will_you_incentivize_them_to_participate: The monetary reward mainly will incentivize them. For those skilled at it, they will make more money for time put in, as opposed to most general easy-for-humans tasks, such as many of the HITs one would find on Amazon's Mechanical Turk. <p>Feeling of contribution<p>human emotion to feel a part of something<p>hone event planning skills<p>training students of hospitality management<p>self fulfilment<p>money<p>payment model with sizeable amount of money from customers<p>orders of magnitude of event planning (amount of questions?)<p>smaller payments for smaller questions<p>user allots amount of paid by important of answer to question<p>every question is separate<p>i need this plan by tomorrow<p>user chooses best solution
  what_will_they_provide_and_what_sort_of_skills_do_they_need: They will provide a detailed plan of every aspect of an event including contracts and invoices from the various companies involved as estimated costs and various logistics as well as a full timeline.
  how_will_you_ensure_the_quality_of_the_crowd_provides: The workers only get paid if the work gets chosen. To weed out nonsense, workers can work together as both internal verification and to mitigate the work, to create an optimal planning experience, where the user will get the most for their money while still receiving quality services and goods. If a worker chooses to work alone, then many (5-10) workers will randomly be assigned to check parts of the submitted data to make sure it's sufficient and appropriate.
  how_will_you_aggregate_the_results_from_the_crowd: The crowd's answers can be broken down into different categories based on event types with many fields in each of these categories. These will all be combined and sent to the user to overview before they choose the winning plan or elements of a plan where the associated workers get paid their portion of the contribution. All non-spam submissions will be shown on the page, then once selected by user, that one goes on the top. 
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: The aggregation of different categories into one coherent report will be done automatically, while the crowd will be filling in these categories with the relevent information.User claims to be planning an event and types/selects questions he needs answers to<p>crowd submits an answer to the question<p>computer can tell you what question to ask because you might not know<p>
  how_will_you_evaluate_if_your_project_is_successful: If users claims satisfaction with event plans, if they were realistic and plausible.<p>If it's a viable business&#58; <p>for-profit, yes<p>costs in website production and databases
  what_potential_problems_do_you_foresee_when_implementing_your_project: All the coding
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108314652 
  name_of_your_project: The Music Database
  give_a_one_sentence_description_of_your_project: The IMDb of music, but assembled by humans.
  what_problem_does_it_solve: There is no comprehensive database of all music, artists, albums, and mixtapes, that ranges from unknown bands to mainstream pop artists. Given this immensity of the music industry, it is a very daunting task to code software that collates all artists and their works without using any crowdsourcing. Furthermore, people around the world have such a diverse taste in music, and can be very big fans of so many artists, that utilizing crowdsourcing may not only build a more comprehensive database, but a more accurate one as well.
  what_similar_projects_exist: Spotify and iTunes have this information, but they are modes of listening to music, and are not music industry databases. This site will be similar to IMDb, but for music instead of movies.
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: Anyone who has access to a computer and internet
  how_will_you_incentivize_them_to_participate: There will not be a monetary incentive to participate, because if the website happens to be successful, there will be a lot of contributors inputting a lot of data, rendering a monetary incentive unfeasible. Instead, a point system will be designed to reward contributors, and bolster their reputation on the site. However, the site will mainly rely on the desire of fans of artists to contribute to those artists’ pages – this may especially be the case for a fan who wants to increase recognition of a relatively unknown band or artist.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: No specific skills are needed, besides information or access to information about an artist that they wish to put on the site. The site will be organized by artist, and each artist’s page will have all of their albums, and all of the songs on each album. A contributor can provide as much or as little information about an artist as they want, so long as it is accurate. 
  how_will_you_ensure_the_quality_of_the_crowd_provides: No specific skills are needed, besides information or access to information about an artist that they wish to put on the site. The site will be organized by artist, and each artist’s page will have all of their albums, and all of the songs on each album. A contributor can provide as much or as little information about an artist as they want, so long as it is accurate. 
  how_will_you_aggregate_the_results_from_the_crowd: The results will be aggregated via an algorithm that takes into account what exactly the contributors are saying about the information that they are editing (whether it agrees or disagrees with the current information), and weighing such contributions based on the points that the contributor has (which is an indication of how reliable the contributor is). 
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: The site will present the crowd with a template that can be filled in with the artist information, making it very easy for contributors, and creating a fairly uniform look throughout the site, much like IMDb. The input of information is all done by the crowd – the crowd will essentially build the whole site. Some quality control algorithms will be implemented, however, such cross checking site information with Spotify’s API. This would be an automated process, not involving the crowd. 
  how_will_you_evaluate_if_your_project_is_successful: The main indication of the success of the project is how many pages accumulate on the site, and how detailed such pages are. A robust implementation would include data about the number of people contributing and using the site, which are also metrics that can indicate success. 
  what_potential_problems_do_you_foresee_when_implementing_your_project: Aggregating the contributor’s and ensuring that the site has accurate information will be a great challenge, but I do not see it is as a problem.  
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108389187
  name_of_your_project: Crowdsourcing for Cash Flows
  give_a_one_sentence_description_of_your_project: Crowdsourcing for Cash Flows is a project designed to harness crowd sourcing to accurately judge the sentiment of articles relating to stocks.
  what_problem_does_it_solve: This helps to solve the problem of market research, and would allow retail investors (people like you and me) to conduct the same sentiment research conducted by analysts at large firms like Goldman Sachs and BlackRock.
  what_similar_projects_exist: There are some sentiment analysis tools available currently.  These include StockFluence, The Stock Sonar, Sentdex, and SNTMNT, all of which perform sentiment analysis on Twitter or other news feeds.  
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: Anybody can be a member of our crowd, as it is easy for humans to determine the sentiment of a piece of written text.  Also, to alleviate concerns about obscure financial terminology, definitions of common terms would be provided.
  how_will_you_incentivize_them_to_participate: We will incentivize them to participate by paying them a certain amount of money for a collection of accurately analyzed text.  For example, we may pay 1 cent per 3 articles read and analyzed.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: These workers will be essentially creating labeled training data for a sentiment classifier algorithm to be trained on.  They only need to be able to read and understand which words are positive, and which words are negative, and how a sentence sentiment consists of the sum of its parts.
  how_will_you_ensure_the_quality_of_the_crowd_provides: I will ensure the quality the crowd provides by creating many test cases on CrowdFlower to ensure the validity of my results.  I will also give a few clear examples, and a list of definitions of commonly used financial terms, so users will understand the articles.
  how_will_you_aggregate_the_results_from_the_crowd: CrowdFlower automatically aggregates the results from the crowd, allowing the job posters (us) to easily download the data once the job is finished.  Additionally, we might break up this data by stock, in order to see which stocks have the brightest outlook.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: First, we will need to create a list of links to online articles and tweets that workers will follow in order to analyze the articles at those links.  To create our test cases, we will follow those links manually, and then analyze those articles ourselves.  Once analyzed, the sentiment will be entered into the CrowdFlower job, and then once the job is finished, we will be able to automatically download this newly labeled data to either train a classifier, or to analyze on our own to determine the best stocks.
  how_will_you_evaluate_if_your_project_is_successful: If we are able to get reliably scored data that is precise and accurate (ideally would love perfect recall, but it is hard to manually score so many articles), then this would be considered a success.  There are many uses for the collected data, from training classifiers to making our own predictions about the stocks.
  what_potential_problems_do_you_foresee_when_implementing_your_project: We foresee a scenario in which some crowd members may not understand some articles due to the financial terminology.  We will try to mitigate these factors by providing workers with definitions of common terms, as well as examples to help them understand how we would like the articles scored.  Additionally, it may be difficult to find huge amounts of articles very easily, and may become a fairly manual task.
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108393795 (password&#58; nets213)
  name_of_your_project: CrowdLove
  give_a_one_sentence_description_of_your_project: CrowdLove uses the crowd to match our users up with suitable partners.
  what_problem_does_it_solve: Online dating/matchmaking. Specifically, people are notoriously bad about answering questions about themselves and knowing what they want. This project takes that out of their handles and lets an objective 3rd party decide on matches.
  what_similar_projects_exist: On Crowd Nine&#58; https://www.oncrowdnine.com/Home/About<p>Chain Date&#58; http://chaindate.com/
  what_type_of_project_is_it: Human computation algorithm
  who_will_be_the_members_of_your_crowd: People on CrowdFlower who describe people based on their social media profiles; People who like matchmaking
  how_will_you_incentivize_them_to_participate: Crowdflower workers will be incentivized by pay<p>Matchmakers will do it for the fun and the satisfaction of being notified when a match works out<p>
  what_will_they_provide_and_what_sort_of_skills_do_they_need: The crowdflower workers will provide the descriptions of the users and need basic skills of knowing english, general cultural phenomena, and being able to make inferences from a person’s photos, statuses, and tweets<p>The matchmakers will provide the actual matches and will need the skill of knowing if two people are meant for each other<p>
  how_will_you_ensure_the_quality_of_the_crowd_provides: We will use multiple HIITs to verify survey answers.<p>Potential matches will be generated on existing similarities (already setting a certain level of quality) and the matches that the matchmakers choose will be only made if multiple matchmakers choose the match.<p>
  how_will_you_aggregate_the_results_from_the_crowd: The survey data will aggregated by what the majority of crowdworkers choose.<p>The potential matches will become matches when a predetermined number of matchmakers vote for a given potential match
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: First, users of the matchmaking service enter links to their social media profiles<p>Next, HIITs are created for crowdworkers to answer survey questions about the person based on the provided social media profiles.<p>These results are aggregated into 5-10 key characteristics about the person.<p>Based on other people with similar characteristics, potential matches are generated for each user.<p>These potential matches are then posted on a site online where matchmakers can vote “yes” or “no” for each potential match. (Tinder / Hot or Not style interface)<p>If a certain potential match reaches a given number of “no” votes, it is removed from the site. If it receives a certain number of “yes” votes before that happens, the two people are sent each other’s social media profiles to get to know each other.<p>For every match that occurs, the matchmakers who voted yes are notified.
  how_will_you_evaluate_if_your_project_is_successful: We could ask users to rate the matches they received and a consistently high rating would inform us of if our project was working.
  what_potential_problems_do_you_foresee_when_implementing_your_project: Some people might be bad matchmakers, or trolls might vote up a bunch of really bad matches
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108394638
  name_of_your_project: MuralMapPhilly
  give_a_one_sentence_description_of_your_project: MuralMapPhilly uses crowdsourcing to create a digital archive of Philadelphia murals
  what_problem_does_it_solve: Philadelphia has a huge variety of beautiful murals interspersed within its area. However, it's difficult for interested parties to know the exact location of all the murals they'd like to see. By creating a digital archive of the existing Philadelphia murals, there will be an easily-accessed documentation of these fantastic works of art.<p>
  what_similar_projects_exist: Mural Locator (http://murallocator.org)<p>City of Philadelphia Mural Arts Program (http://www.muralarts.org/)
  what_type_of_project_is_it: A tool for crowdsourcing
  who_will_be_the_members_of_your_crowd: People knowledgeable about existing Philadelphia murals
  how_will_you_incentivize_them_to_participate: This project is for the general good/knowledge of Philadelphia and those interested in Philadelphia murals. It's particularly useful for experts on Philadelphia murals, who would utilize this in papers, presentations, and other parts of their work. 
  what_will_they_provide_and_what_sort_of_skills_do_they_need: Members will provide information about locations, painters, titles, and other relevant information of Philadelphia murals. After murals have been tagged, other members will verify whether the provided information is correct. These two tasks require a knowledge of existing Philadelphia murals.
  how_will_you_ensure_the_quality_of_the_crowd_provides: Quality will be verified through a second round of workers that provide appropriate documentation (pictures with context, online links, etc.) that inputted mural information is correct.
  how_will_you_aggregate_the_results_from_the_crowd: The crowd will map murals onto an online map of Philadelphia; the second round of crowd workers will verify murals on this map.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: An online map of Philadelphia that allows people to add mural locations and relevant information will have to be generated. From here, crowd workers will have to add a certain number of murals (3 - 5) per task to the map. A second round of crowd workers will verify these murals. After this has been done, a large number of murals will have been aggregated onto the map, which can be added to and verified by the general public.
  how_will_you_evaluate_if_your_project_is_successful: The project will be successful if it provides a better way of Philadelphia mural documentation than already exists. It should be easy for murals to be found by name, location, artists, or other relevant information. 
  what_potential_problems_do_you_foresee_when_implementing_your_project: It may be difficult to find enough people knowledgeable about the location of Philadelphia murals. CrowdFlower has also proved to be extensive, and it's possible that 2 rounds of crowdworkers may not be plausible. 
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108338175
  name_of_your_project: PennImpact
  give_a_one_sentence_description_of_your_project: PennImpact will be a online platform for student to come together and collaborate on proposals to change the administration.
  what_problem_does_it_solve: We looked into how one would petition the school to change its policy, and we could only find petitions for individuals to get out of certain course requirements. This is not to say there are not ways to propose change to the administration, but as far as we know, there isn't really a standardized way to do so. We believe an online platform would not only centralize the process, but also streamline it and allow more individuals from a greater variety of backgrounds to participate.
  what_similar_projects_exist: change.org, the Icelandic Constitution reform project
  what_type_of_project_is_it: crowdsourcing + social impact
  who_will_be_the_members_of_your_crowd: Members of the penn community
  how_will_you_incentivize_them_to_participate: Hopefully, a desire to do good and be heard.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: They wil provide the actual substance of the site. There does not need to be a particular skill, but they should be able to express their ideas and have an insight into the Penn community.
  how_will_you_ensure_the_quality_of_the_crowd_provides: We hope that the factor that motivates people to participate will also motivate them to produce better quality input. However, we will look into a curation system and rating/voting system to float good idea to the top and get rid of spam.
  how_will_you_aggregate_the_results_from_the_crowd: On a centralized web platform for the Penn community to access.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: We will need to create the actual website, which should have a standardized and easy to use user interface. We will also need to put in place the curation and quality insurance safe guards. But the actual content will be supplied by the crowd.
  how_will_you_evaluate_if_your_project_is_successful: Based upon the participation numbers.
  what_potential_problems_do_you_foresee_when_implementing_your_project: Quality control is always an issue. Possible issues with the administration? 
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108338175
  name_of_your_project: Quakr
  give_a_one_sentence_description_of_your_project: Quakr is an online dating platform that uses crowdsourcing as a matchmatcher.
  what_problem_does_it_solve: A lot of online dating platforms already exist, but these platforms primarily use some kind of computer algorithm to measure the traits of its users and assign some king of compatibility. Learning about how the aggregation of data across a large, diverse, and independently crowd can often yield better result than that of a single 'expert', we wanted to see if a crowdsourced compatibility rating would be better than a computer algorithm generated by 'experts'. This dating application also opened up the opportunity to collect some interesting data on dating, which is why we want to see if there is a wide diversity of what people look for in a match or not and if what people look at in other's matches is what they look for in their own.
  what_similar_projects_exist: OkCupid, ChristianMingle, Match.com
  what_type_of_project_is_it: Social science experiment with the crowd, A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: Mechanical Turkers
  how_will_you_incentivize_them_to_participate: A small monetary reward for evaluating a certain number of matches and explaining their criterion/criteria.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: They will provide an opinion on whether or not they think two people are a good match. They need a basic understanding of people, but we are not looking for any particular expertise.
  how_will_you_ensure_the_quality_of_the_crowd_provides: We will ask to type what criteria/criterion they used to evaluate what would be a good match. This will help prevent against bots and hopefully make the turkers think about a match more carefully. 
  how_will_you_aggregate_the_results_from_the_crowd: Average the compatibility ratings of a given couple given by the Turkers.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: The profile information will be supplied by users. We will block the pictures and names as to make it a blind assessment. The pairs given to the turkers to evaluate will be done automatically and then the workers will supply a compatibility rating. We will collect all of the responses, average the responses for a couple, and alert them as to what their matches were above a certain threshold. 
  how_will_you_evaluate_if_your_project_is_successful: If we were to actually implement this, we would ask the couples for feedback. The more positive the feedback the more successful our endeavor will have been. It would be nice if we had access to a matching algorithm to compare with, but we are not sure how we would go about finding or implementing one. 
  what_potential_problems_do_you_foresee_when_implementing_your_project: Poor quality data is always a concern. Also poor quality input from the users and possibly motivating users to try our service. 
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108384165
  name_of_your_project: Venn
  give_a_one_sentence_description_of_your_project: Venn uses human computation to bridge social circles by making personalized suggestions for platonic connections.
  what_problem_does_it_solve: The human condition suggests that all people are constantly looking for meaningful friendships and connections. There are a few apps and platforms that exist for this purpose; however, for the most part, platonic matchmaking services don’t have the same matching algorithms that Match.com or OkCupid do. In addition, one’s online profile or answers to a matchmaking questionnaire may not necessarily equate their personality. Venn uses human computation to suggest friends, ensuring a more personalized approach.
  what_similar_projects_exist: Facebook’s “Suggested Friends” function<p>Women-only social networking websites&#58; <p>GirlFriendCircles.com, GirlfriendSocial.com, SocialJane.com<p>All-gender platonic matchmaking&#58; not4dating.com, bestfriendmatch.com<p>
  what_type_of_project_is_it: Human computation algorithm
  who_will_be_the_members_of_your_crowd: Anybody who chooses to use the app. We would probably launch at Penn, but the nature of the app allows any kind of user.
  how_will_you_incentivize_them_to_participate: Participation allows for personalized friend suggestions (ultimate benefit to the user, and the purpose of the app)<p>Fun quizlet interface <p>Point system for successful matches<p>Bridging social circles allows user to integrate previously separate friend groups<p>
  what_will_they_provide_and_what_sort_of_skills_do_they_need: Users will be given information (e.g., hobbies, passions, music taste, Q&A)  about two different Venn users, and must use this information to decide if those two users would be compatible friends. In addition, users will also be prompted to answer fun questions of their own about their hobbies, personalities, etc. Users must be able to read English and physically interact with the application. In addition, they should be able to pick up on contextual clues and able to extract similarities and incompatibilities from the given information.
  how_will_you_ensure_the_quality_of_the_crowd_provides: Each user is motivated to provide “good” judgements because the app largely focuses on bringing together the user’s friends from different social circles. Therefore, the matchmaking questions tend to involve a user’s friends, whom the user (ideally) cares about and would not troll for no reason. In addition, a user who lies on the personal questions will simply ruin the app for himself, and nothing else.
  how_will_you_aggregate_the_results_from_the_crowd: Some algorithm will be created to sum all the “Would A and B be friends? YES/NO” results for each pair. If the amount of YES’s crosses a certain percentage, A and B will become suggested friends. <p>Additionally, all personal questions answered by each individual user will feed back into their profile, which will show up in matchmaking questions involving that user.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: Venn integrates with your social media accounts to aggregate your likes, interests, and friends. There may be a machine learning component involved in this, wherein Venn pulls information from your statuses, likes, comments, and events attended to create a database of your hobbies, passions, etc.<p>Users can begin to interact with the Venn interface, which has two sets of question prompts&#58;<p>Users answer questions about themselves (e.g., “Would you rather A or B?” “What describes you best&#58; …,” “What are your hobbies?”)<p>Users are given information about two other users, and must decide if they would be a compatible friendship match<p>Based on the information provided by the crowd in step 2, users are given suggested friends, tailored to their personalities.<p>Venn will redirect back to a messaging application (e.g., FB Messenger) that will allow you to reach out to your suggested friends.<p>Users can mark suggested friendships as successful or not successful, which will feed back into the system for training purposes AND which will also allow users to check on the status of their suggested friendships.<p>Repeat!<p>
  how_will_you_evaluate_if_your_project_is_successful: The project will be considered successful if it manages to actually facilitate new friendships! The app will keep track of all suggested connections and all successful connections, which will both be used to encourage more matches and to evaluate the project’s overall success.<p>
  what_potential_problems_do_you_foresee_when_implementing_your_project: Lack of participation.<p>Accurately predicting good friendship matches (may need to include a testing component)<p>Making sure that suggested friends actually follow up on meeting each other<p>
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108394538
  name_of_your_project: The Lazy Analyst
  give_a_one_sentence_description_of_your_project: Application that helps calculate the valuation of a company by determining similar publicly traded companies.
  what_problem_does_it_solve: To value a private company, a common method is to look at the financials of similar publicly traded companies. However, before even looking at financial documents, analysts typically waste many hours trying to determine companies similar to the company they are valuing.
  what_similar_projects_exist: Given a public company, CapIQ, Google Finance, and Bloomberg try to provide a list of similar publicly traded companies with limited success.
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: Turkers, CrowdFlowerers, and/or other crowdsourcing site workers
  how_will_you_incentivize_them_to_participate: Paying them for each HIT.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: The crowdsourcing website workers will be given basic information on the target company and a publicly traded company. They will then rate how similar the publicly traded company is to the target company based on the information provided.
  how_will_you_ensure_the_quality_of_the_crowd_provides: MTurk and Crowdflower have nifty features that allow us to filter workers based on trust level and performance. Crowdflower also allows us to set some test questions that could be used to filter out untrustworthy workers. In addition, we will have five workers for each description to help remove individual bias.
  how_will_you_aggregate_the_results_from_the_crowd: For each publicly traded company that we are comparing to the target company, we would average the 5 similarity ratings provided by the workers. We would then return the top 10 companies with the highest similarity rating.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: The user will input a description of his target company and provide one publicly traded company with a similar business model. Using the Yahoo Finance API (or another financial website API) an algorithm looks up comparable companies for this first provided company. For each of these companies, it looks up their comparable companies. This process should result in a list of around 75 potentially similar companies. Using the API, pull up the 75 descriptions for these companies and input them into Crowdflower. Five Turkers will compare each public company description with the description provided of the user’s target company and determine if the company is very similar (3), kind of similar (2), or not similar at all (1). In the end, take the top 10 companies with the highest score.
  how_will_you_evaluate_if_your_project_is_successful: Run the Lazy Analyst on a company like Toys-R-Us and see what ten companies are produced by the crowdsourcing website workers. If the list of companies are all pretty comparable, then we will have a smashing success on our hands that is ready to be bought up by Bloomberg for millions.
  what_potential_problems_do_you_foresee_when_implementing_your_project: There is always the worry of Turkers providing unreliable results, despite the quality assurance measures we put in place. Also, there is the potential issue of there being more than ten highly rated companies at the end of the process. In addition, some of the companies in more obscure industries (i.e. non-consumer goods) will be hard to understand or compare for the average layman.
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108395277
  name_of_your_project: Mooch
  give_a_one_sentence_description_of_your_project: Mooch is network of borrowers and lenders of basics that the average college student or apartment might lack.
  what_problem_does_it_solve: Mooch connects students who need tools, appliances, and other odds and ends (the “Moochers”) to the people who are willing to lend them these items on a temporary basis (the “Givers”).
  what_similar_projects_exist: Rent the Runway (for high end dresses rented by female borrowers), Car sharing (Zipcar), Bike sharing, Kitchen Share NE, Airbnb. The Airbnb concept of, “Use my ___ while I’m not using it,” is closest to what we’re trying to achieve with Mooch.
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: University Students
  how_will_you_incentivize_them_to_participate: They will borrow because they sometimes need an iron, drill, or leaf blower that they may not have! They will lend for money.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: They don’t need any special skills, but they do need money and/or material possessions that could be listed on Mooch. They also need to be responsible enough to use and return items undamaged, and open to allowing others to borrow those possessions.
  how_will_you_ensure_the_quality_of_the_crowd_provides: Using money to reward Givers, and access to items on Mooch to reward Borrowers. Every Giver will need to post pictures of the item their listing to lend (protecting against false claims). Every Moocher will be prompted to review each Mooching experience, rating the lender and the item they borrowed. Because of the proximity of the lenders and borrowers, people who are lending items to people “mooching” will delivery it to them directly. When this happens, both the Giver and Moocher will register the item as “delivered” on the interface. Discrepancy in this will prompt administrator investigation.
  how_will_you_aggregate_the_results_from_the_crowd: Publicly display the average star ratings for lenders, forcibly remove Givers who have a repeated problems with item delivery, forcibly remove Moochers who don’t follow through on payments or returning items.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: Get Givers to sign up<p>Get Moochers to sign up<p>Pilot and Oversee the first lend-and-borrow transactions<p>Collect reviews around Giver and Moocher experience<p>Run A/B testing for alternative payment, scheduling, and delivery schema<p>Expand the community!<p>
  how_will_you_evaluate_if_your_project_is_successful: The number of successful lend-borrow-return transactions, the number of active users, the percentage of times that a Moocher can find and attain an item they need, the percentage of items that a Giver gets back in the same condition in which they lent it, sentiment analysis of the user experience reviews.<p>
  what_potential_problems_do_you_foresee_when_implementing_your_project: The biggest pitfall is the risk of damaged or unreturned items. We’ll have to set up a network culture that forges trust between Givers and Moochers, even if they haven’t met.<p>Logistical issues around payment and scheduling, too. Will we let Moochers and Givers work out the payment (or no payment -- can be free lending!) between themselves? Or will we enable transactions over the website for payment? Scheduling a common time for item delivery should be initiated by the Moocher, and shouldn’t be too difficult to work out if they list daily availability on a profile.<p>
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108384164
  name_of_your_project: Radicle
  give_a_one_sentence_description_of_your_project: Radicle is a social experiment and crowd-powered data germination platform. 
  what_problem_does_it_solve: It gets the crowd to answer the questions that have remained dormant among them.
  what_similar_projects_exist: Isolated research projects poll answers to questions that a single person or a group of people created. Forums and discussion boards allow individuals to post questions for the crowd to answer. However, no project exists that combines crowd-powered questions with crowd-powered answers, then gives that data back to the crowd.
  what_type_of_project_is_it: Social science experiment with the crowd, A tool for crowdsourcing
  who_will_be_the_members_of_your_crowd: To start, the Penn student community. To finish, either the Penn student community or the wider world of crowdworkers on Amazon MTurk /Crowdflower (or both!) could answer the questions.
  how_will_you_incentivize_them_to_participate: For the crowd workers on MTurk and Crowdflower, it will have to be with money. For the students, the incentive is answers to questions around issues that interest them, curated in an appealing and revealing way.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: The crowd will propose questions to crowdsource answers to, submit votes and revisions on those questions, and, finally, answers to the questions.
  how_will_you_ensure_the_quality_of_the_crowd_provides: Within the Penn student community crowd, we can be fairly sure that participants will provide reliable data. For the wider community of crowd workers, we will use the tools on Crowdflower to weed out extraneous answers and bots.
  how_will_you_aggregate_the_results_from_the_crowd: We’ll pick questions to field for crowdsourced answers on Radicle based on which get the highest number of votes and most revision activity. For the question answers, it depends on the type of question that is fielded. For yes or no questions, we can parse answers into simple percentages. For opinion questions that ask the person to chose a range of “strongly agree” to “strongly disagree” with a statement, we’ll represent this with a continuum style data representation.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: Test phase&#58;<p>1) Field a survey of questions around the issue of Campus Sexual Assault to the Penn student community “crowd”<p>2) Aggregate and Evaluate Data<p>3) Create Data Visualization from further Analysis<p>Rollout phase&#58;<p>1) Forum Phase<p>- Allow users to propose questions they want answered by the crowd<p>- Allow users to vote on and suggest revisions to questions they also want answered<p>2) Polling Phase<p>- Field the most popular questions to the crowd for data acquisition<p>- Repeat steps 2 and 3 of Test phase<p>
  how_will_you_evaluate_if_your_project_is_successful: By the number of people who are actively participating -- proposing questions, voting on questions, answering questions, and creating buzz around the question results. Basically, by evaluating buzz and traffic.
  what_potential_problems_do_you_foresee_when_implementing_your_project: Incentivizing the four aspects of active participation described above. Since student participation would not be paid, we could put people with “winning questions” in the spotlight or build in some human aspect to the answering.
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108390839
  name_of_your_project: Read it Out
  give_a_one_sentence_description_of_your_project: crowdsourced audio book
  what_problem_does_it_solve: It will compile an audio book in a more efficient way by crowdsourcing audio files from different users using different languages<p>
  what_similar_projects_exist: LibriVox, SpokenHerd, WeChat Voice Donor
  what_type_of_project_is_it: Human computation algorithm, A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: People who love to read
  how_will_you_incentivize_them_to_participate: Fun  –  Contribute to an Open Source Project and get your name on the credits of the audiobook<p>Money – Get paid for your voice<p>Charity – “The Voice Donor” Concept<p>
  what_will_they_provide_and_what_sort_of_skills_do_they_need: Their Voice – Those who read the paragraphs<p>Their feedback – Those who review recordings for clarity (Quality Control)<p>Ability to Read and Speak the Language of the audiobook!<p>Clear and coherent diction<p>The ability to spell! (Or use a spell-checker atleast…) <p>
  how_will_you_ensure_the_quality_of_the_crowd_provides: We will have a second round of crowdsourcing after collecting all the audio files to ask the crowd to rate whether this audio file a) is saying exactly what was in the assigned paragraph and b) is of enough quality (diction, clarity, volume, emotion, etc)
  how_will_you_aggregate_the_results_from_the_crowd: For the first round, we will collect all the voices by users - audio files and save them alongside with the text correspondingly assigned<p>For the second round, we will reject those low-quality files as identified by the crowd and accept the good ones.<p>Eventually we will compile separate files together according to the order of the text
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: 1. Break down texts to paragraphs<p>2. Assign each paragraph to a user in the crowd and ask him/her to read it out and record it<p>3. Collect all the audio files by different users<p>4. Assign each audio file with its corresponding text to the crowd to identify whether it's high-quality<p>5. Compile of-quality audio files into an audio book
  how_will_you_evaluate_if_your_project_is_successful: To be able to create a platform to create audio books for all books in the public domain<p>To compile 2-3 books with high quality as checked/listened by team members
  what_potential_problems_do_you_foresee_when_implementing_your_project: The size of all the audio files might be too big to host and to compile<p>Different reading styles in different audio files might jeopardize the overall consistent flow of the audio book when compiled together
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108387621
  name_of_your_project: Lineless - Why Wait?
  give_a_one_sentence_description_of_your_project: An app that crowdsources information about the wait times at local restaurants and food trucks
  what_problem_does_it_solve: It helps people predict wait times so that they can optimize their choice of where to go for food, especially when on a tight schedule.
  what_similar_projects_exist: I saw a few alternatives mentioned in articles online (such as What's The Wait and Waitlist.  Both supposedly have iPhone apps, but I was not able to find them on the app store.  Neither of these would include food trucks though, so there is still added value from our version of this concept.
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: People within a target geographic region.  For now, UPenn students, faculty, and staff, and other West Philly residents as well.
  how_will_you_incentivize_them_to_participate: We believe that many people will find it useful enough to contribute, but we also could employ gamification to solicit contributions.  Additionally, when lines are long, people have plenty of time with nothing to do, so it should be feasible to get people to submit responses while they are waiting.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: They will provide estimates of the number of people in line at a location, and the average speed that the line is moving.  They don't need any specific skills.
  how_will_you_ensure_the_quality_of_the_crowd_provides: We can have an option for people to report if the app's data is not accurate at an individual location, and we can also require a certain number of consistent reports before we update the information displayed by the app.
  how_will_you_aggregate_the_results_from_the_crowd: We would incorporate them into algorithms to estimate crowd flow and line progression.  Included in that would be some sort of average value for the length of the wait at a restaurant.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: People would report their firsthand encounters with wait-times at specific restaurants around campus, and the app would aggregate them and incorporate the data into algorithms to provide an estimate.
  how_will_you_evaluate_if_your_project_is_successful: By evaluating the estimates for accuracy and comparing them to other predictions that people have about when the waits will be long.
  what_potential_problems_do_you_foresee_when_implementing_your_project: 1) This might be a little ambitious to complete in its entirety in the time-frame we have.<p>2) It relies on large amounts of data in order to be accurate.  It might be hard to get enough people to contribute consistently enough.
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108398059
  name_of_your_project: First Impressions and PSG Elections
  give_a_one_sentence_description_of_your_project: How first impressions of competence, trustworthiness, and other attributes correlate with Penn Student Government Election results
  what_problem_does_it_solve: There is a large body of research regarding instantaneous judgements of two individuals’ faces and how that correlates to the results of an election between the two candidates. For example, Source 1 (see next question) shows that  inferences of competence based solely on facial appearance predicted the outcomes of U.S. congressional elections at a rate of 68%. Source 2 also explores trustworthiness and dominance. Source 3 looks at attractiveness, deceitfulness, and threat.<p>Our proposal involves performing this same experiment, where Penn Student Government candidates are the subjects. Compared to the elections considered in previous studies (i.e. U.S. Senate and House, gubernatorial, and other prominent elections), PSG elections provide far less visibility for candidates, particularly for any election beyond the Undergraduate Assembly President and Vice President. <p>The experiment will be run via crowdsourcing. We will have crowd workers view two candidates’ faces side-by-side and answer a question like, “Which person is more trustworthy?” or “Which person is more competent?” We will then aggregate these results across all elections and compare the ranking of each characteristic to the actual results of the election. Ultimately, we will make a conclusion as to whether or not PSG elections hold the same characteristics of being correlated to various snap judgements as other more prominent elections.
  what_similar_projects_exist: Source 1&#58; Inferences of Competence from Faces Predict Election Outcomes&#58; https://psych.princeton.edu/psychology/research/todorov/pdf/Todorov_Science2005.pdf<p>Source 2&#58; Need to Get Elected? Looking Competent and Trustworthy, but not Dominant<p>http://www.psych.udel.edu/pdfs/publications/Face_Study.pdf<p>Source 3&#58; Predicting Election Outcomes from Positive and Negative Trait<p>Assessments of Candidate Images<p>http://people.hss.caltech.edu/~rma/Election%20Outcomes%20and%20Trait%20Assessments_02.pdf<p>Our project brings the novel approach of having the crowd do the evaluation. This can give us a more larger and more diverse sample size. For example, in Source 3, the evaluators were “43 paid graduate and undergraduate students at the California Institute of Technology.” With crowdsourced micropayments, we can get far more judgements from far more people.
  what_type_of_project_is_it: Social science experiment with the crowd
  who_will_be_the_members_of_your_crowd: We will use CrowdFlower workers to answer our judgement questions.
  how_will_you_incentivize_them_to_participate: We will give them micropayments for each judgement that they make. We will also make funny control questions to make the experience more enjoyable.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: The only skill they need is the ability to read English. They will simply look at side-by-side pictures of individuals and make judgements accordingly. I suppose this task would be difficult for someone with Autism due to their difficulty with understanding facial expressions.
  how_will_you_ensure_the_quality_of_the_crowd_provides: In order to ensure that workers are not randomly selecting answers, we will include some test questions. These test questions will put two pictures side-by-side. For example, we could have one picture of a cat with its tongue sticking out, and one picture of a dog with its mouth closed. We will then ask, “Please select the animal whose tongue is visible.” This will ensure that people are actually looking at the pictures and thoughtfully answering the questions.
  how_will_you_aggregate_the_results_from_the_crowd: We will ask the crowd to evaluate every single pair of candidates running against each other. We will then add up each evaluation to select the candidate from each pair that gains a majority of the votes. We hope to get a complete ranking of the candidates from this. If we get a cycle (i.e. A>B, B>C, C>A), then we will need to continue to evaluate these pairs until a proper ranking emerges.<p>Once we have a complete ranking, then we will compare that to the true results of the elections. We will use statistical tools like linear regression to try to identify correlations.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: 1. Obtain images of each candidate from the Spring 2014 PSG Elections (http://www.thedp.com/section/spring-2014-board-elections-center, http://www.thedp.com/section/spring-2014-ua-elections-center) <p>2. Put the images into a csv format that is compatible with CrowdFlower, where each line contains the images of two candidates who ran against each other. The HIT will create questions regarding the candidates’ trustworthiness, competence, and other variables.<p>3. We will create a program that will parse through all of the results from CrowdFlower and create rankings for each of the elections along each of the variables.<p>4. We will then use linear regression to compare the actual results of the elections to the workers’ rankings of the candidates.<p>5. We will draw general conclusions from the correlations (or lack thereof) between each of our different criteria and candidates’ success in PSG elections.
  how_will_you_evaluate_if_your_project_is_successful: Ultimately, we hope to make conclusions regarding the correlation between individuals’ snap judgements of various characteristics of candidates and their success in PSG elections. For example, we may conclude that there is no correlation between how trustworthy people believe that a candidate’s face looks and her success in the election. We would suggest that this could be explained by the low visibility of candidates in PSG elections in comparison to more prominent elections studied previously.
  what_potential_problems_do_you_foresee_when_implementing_your_project: Here are the number of candidates running in each contested election (sources&#58; http://www.penn-nec.org/2014/03/spring-2014-official-results-class-boards/ and http://www.penn-nec.org/2014/03/spring-2014-official-results-undergraduate-assembly/)&#58;<p>Position (number candidates, number of pairwise comparisons)<p>2015 VP External (2, 1)<p>2015 VP Internal (2, 1)<p>2016 Engineering (2, 1)<p>2016 Wharton (2, 1)<p>2017 President (2, 1)<p>2017 Executive VP (2, 1)<p>2017 VP External (4, 6)<p>2017 VP Finances (3, 3)<p>2017 College (3, 3)<p>2017 Nursing (2, 1)<p>UA Engineering (7, 21)<p>UA College (20, 190)<p>UA VP (2, 1)<p>UA President (2, 1)<p>This makes for 232 total comparisons. We are unsure whether this is a lot, a few, or somewhere in between. This will depend on how many characteristics we decide to evaluate, how many comparisons we think will be necessary for us to confidently pass a judgement on our rankings, and how much we will pay per judgement. All of these factors will have to be carefully considered as we are building our CrowdFlower project.<p>Additionally, there may be an ethical issue with putting individuals’ photos on CrowdFlower without their approval. While the photos are in the public domain, we may need to consider asking each of the candidates if they approve of us using their photo.
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108341677
  name_of_your_project: MassterMix
  give_a_one_sentence_description_of_your_project: MassterMix is a music curation service that helps users create a playlist for any occasion.
  what_problem_does_it_solve: There are over 20,000,000 songs that are only a click away, and each of us has different music needs (based off our mood, or for events etc). Pandora, Spotify, Songza and Rdio are close to finding the right song for the occasion but haven't replaced DJs - and sometimes the matches are just plain wrong. MassterMix solves the need to create the best playlist that you need for any moment. 
  what_similar_projects_exist: Roqbot, Anthm, Spotify, Rdio, Songza and Pandora.
  what_type_of_project_is_it: Human computation algorithm, A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: Self proclaimed music aficionados
  how_will_you_incentivize_them_to_participate: They will receive cash compensation for each recommendation they stated/voted up to be on the playlist. Also, they will have access to the completed playlist once the playlist has been finalized!
  what_will_they_provide_and_what_sort_of_skills_do_they_need: They need to have an understanding of music - understand that it's not just about noise, but about the sentiment and feelings behind the sounds. They need to know the difference between Rap and EDM, while at the same time think beyond just music genre's.
  how_will_you_ensure_the_quality_of_the_crowd_provides: They're will be multiple quizzes - 4 songs on a list, which does not belong, and also, tasked to choose the right songs for a playlist prompt Make a mellow playlist.
  how_will_you_aggregate_the_results_from_the_crowd: The results will be songs voted up to the community as most likely to be placed on the list and least likely to match the mood. This will be done by either collected suggestions or by votes on current suggestions. 
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: The user will type the name of the playlist - what the purpose/intent is for - what mood they are going for, and what parameters of songs they don't want on the list (ie no Bieber). Then you add 2-3 songs to start off the playlist and send the spotify url posted to the crowd site. The crowd will then start a radio based off the songs on their own spotify, and choose which of the selection fits best - or plainly write the name of the song they know will fit. The list generation and voting will be done automatically. 
  how_will_you_evaluate_if_your_project_is_successful: The user will reject/accept the end collective playlist - and they can rate how close/perfect the event was for the event.
  what_potential_problems_do_you_foresee_when_implementing_your_project: Musical tastes may differ - and the person may reject all recommendations - there also may be a language barrier and the potential to spam songs that have no relation to the playlist. 
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108309538
  name_of_your_project: Social Scrub - Cleansing Your Employees' Social Media Profiles
  give_a_one_sentence_description_of_your_project: Use crowdworkers to flag inappopriate social media posts authored by a company's employees.
  what_problem_does_it_solve: Companies want to maintain a positive outward image. One aspect of this outward image is posts made by a company's employees to social media sites. Companies want to be sure that these posts do not reflect poorly on the organization, thus they seek to flag inappropriate posts and have them removed by the poster.
  what_similar_projects_exist: Different companies have internal (unpublicized) methods of monotoring employee social media profiles, but these searches can often require internal company labor to do the searching. This makes for a more costly search.
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: Crowdflower workers
  how_will_you_incentivize_them_to_participate: Payments per HITs completed, which would be funded by the fee companies would pay for the service.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: They will provide a judgement on whether a post is inappropriate or not. This would simply require English language skills.
  how_will_you_ensure_the_quality_of_the_crowd_provides: A ML algorithm will be used to filter out samples of tweets which are more likely to be considered appropriate. If multiple crowdworkers agree that the post in inappropriate, it can be confidently flagged. If a disagreement exists between the algorithm and the crowd, additional workers could be sourced to reach a more confident conclusion.
  how_will_you_aggregate_the_results_from_the_crowd: Using Crowdflower's results aggregation features.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: First, a web-scraping mechanism would pull tweets from a user's publicly available profile. An algorithm would automatically pull a sample of these tweets that are considered more likely to be inappropriate. This would be done using a similarly structured classifier as the gun articles classifier. These tweets would then be sent to crowdworkers and so that they can provide opinions on a tweet's appropriateness. Each tweet would be viewed by multiple workers. Tweets which can be confidently flagged are flagged. Lastly, users which have a high volume of flagged tweets are themselves flagged, so that supervising members of the employing company can do a further investigation of the profile.
  how_will_you_evaluate_if_your_project_is_successful: The project is successful if the process results in a reasonable number of flagged tweets, and among these flagged tweets, a company's HR department could reasonably agree in the classification as inappropriate.
  what_potential_problems_do_you_foresee_when_implementing_your_project: The biggest potential problems stem from inaccurate classifications of appropriate/inappropriate. Companies paying for the service will not be satisfied if the process does not accurately flag an overwhelming majority of inappropriate tweets. Employees will be unsatisfied if tweets which should not be flagged are flagged by the process.
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108309978
  name_of_your_project: The Weighing of the Bull
  give_a_one_sentence_description_of_your_project: Research project that looks to analyze some relationship between the stock opinions of random people on MechanicalTurk and the actual market shifts.
  what_problem_does_it_solve: This problem could reveal some interesting similarities or differences between the stock opinions of the crowd and actual stock trends.  Like The Weighing of The Bull example, this experiment takes the Wisdom of Crowds to a whole new level.  
  what_similar_projects_exist: None that we have found that specifically use many human opinions as opposed to econometrics.  
  what_type_of_project_is_it: Social science experiment with the crowd
  who_will_be_the_members_of_your_crowd: The members of our crown would be any US citizen participating on CrowdFlower
  how_will_you_incentivize_them_to_participate: We would make our hits worth a fair amount of money for their time.  Because this could be time extensive--as far as a Hit is concerned--we would need to pay workers more than one or two cents.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: They wouldn't need any skills to begin.  First, we would give workers a lesson on economics that goes over some key factors analysts take into consideration.  Then, crowd workers would receive a link to the Quick Facts page of the particular stock along with links to a few articles describing recent activity and anything we believe is important.  This makes the opinion more of the average man, and guarantees that our results can be compared with someone who is just entering, or has very little experience trading stocks.  
  how_will_you_ensure_the_quality_of_the_crowd_provides: We will have many workers submit feedback per stock, making any outliers less weighted in our results.  Also, we will look at the timestamp--if the worker spent less than a certain time we set, they will not be approved.  
  how_will_you_aggregate_the_results_from_the_crowd: CrowdFlower offers many recording functions that we will be using to aggregate our data.  Also, we will probably be using some R coding to analyze our results.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: Steps&#58;<p>1.  Create survey and decide on important metrics<p>2.  Write program that crawls the web for relevant, recent articles about a specific stock and grabs its Yahoo Finance Summary for the worker<p>3.  Check Data for accuracy/quality <p>4.  Analyze results
  how_will_you_evaluate_if_your_project_is_successful: If we get trustworthy data, our results will be successful regardless of how closely they match with the actual market.  The differences, in fact would be of greater interest.
  what_potential_problems_do_you_foresee_when_implementing_your_project: Some problems could include not getting workers on CrowdFlower who actually do the research, not finding enough people to complete our survey, being unable to find any statistical value in our data, and various latency issues.     
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108310922
  name_of_your_project: PReTweet
  give_a_one_sentence_description_of_your_project: PReTweet allows people and companies to test the quality (appropriateness, humor, factuality) of a tweet before tweeting it.
  what_problem_does_it_solve: PReTweet screens tweets before they are tweeted. In today's world, people and companies are constantly tweeting, sometimes without thinking of the ramifications. PReTweet allows for companies to preview the content of tweets before they are tweeted. This will prevent people and companies from tweeting offensive content. Furthermore, this could also help people and companies gauge which tweets will be the most effective and memorable.
  what_similar_projects_exist: We could not find any similar products.
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: Crowd Flower workers
  how_will_you_incentivize_them_to_participate: We will pay workers to screen tweets.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: Workers will answer simple questions about tweets such as Is this tweet appropriate?, Which of these tweets is funniest?, and Which of these tweets is most interesting?.
  how_will_you_ensure_the_quality_of_the_crowd_provides: We will have test questions which will gauge whether a worker can accurately describe and analyze tweets. Furthermore, we will have multiple workers preview each set of tweets and only count the responses which are agreed upon by several workers.
  how_will_you_aggregate_the_results_from_the_crowd: We will aggregate the results using the reporting functions of Crowd Flower.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: We will receive a list of tweets (from a company or person) to be previewed. We will show these tweets to the crowdworkers, along with the question of interest (Is this tweet appropriate?, Which tweet is funniest?) and ask for their opinions. We will aggregate these results to determine if and which tweet should be chosen as the final tweet.
  how_will_you_evaluate_if_your_project_is_successful: We will evaluate if our project is successful by testing the crowdworkers with actual tweets or by testing the chosen tweets on twitter. The first case involves determining whether crowdworkers can determine if tweets are appropriate in content. Furthermore, we will test which tweet is determined to be the best by the crowdsourcers and then check if that tweet does indeed receive the most favorites and retweets on Twitter.
  what_potential_problems_do_you_foresee_when_implementing_your_project: We will need to ensure that we get a large and diverse sample size of crowdsourcers. If we don't have enough size and diversity, our previews will not be representative of the population which will view the eventual tweet. This could be problematic, especially because of the large variance of words' connotations.
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108012062
  name_of_your_project: Priming Workers
  give_a_one_sentence_description_of_your_project: Show that we can manipulate what people value and what information they deem most relevant by priming them with input from that subject area.
  what_problem_does_it_solve: This problem addresses how people think and how we can be influenced by external information that they are exposed to prior to a decision. This can help in trying to remove biases from important decisions and can be leveraged for advertising and public campaigns like eating healthy, anti-bullying, dropping out of high school, etc. 
  what_similar_projects_exist: There has been a lot of research in the area of priming, showing that it is an effective tool in influencing behavior. Often, these are done on test subjects compensated for participating in the entire study, so it will be interesting to test from a crowd sourcing perspective where workers are paid on a per-job basis, so those who want/need more money will be primed more, and to see if this has any effect on the final results. 
  what_type_of_project_is_it: Social science experiment with the crowd
  who_will_be_the_members_of_your_crowd: CrowdFlower workers
  how_will_you_incentivize_them_to_participate: They will be paid for performing jobs on crowdflower. We will also try to make the tasks engaging to try and keep workers stimulated since priming is a two part experiment, and we need workers to complete both sections to get pertinent results. 
  what_will_they_provide_and_what_sort_of_skills_do_they_need: This is not a complex task and does not require any prior skills. They will be primed by performing a very simple task on a control or test of data (pictures, words, shapes, etc.) that will prime them to focus on something in specific (or, in the case of the control, will keep them unprimed). Then, they will answer a set of questions that relate to the subject they were primed for, and we will test of those who were primed were more likely to answer in a certain way, focus on given criteria, etc. 
  how_will_you_ensure_the_quality_of_the_crowd_provides: For the first set of priming questions, there are concrete right and wrong answers (counting syllables in a word, for example), so that will be easy to check. The next set of questions will be qualitative, with no right answer since we are testing if we can influence people to answer in a certain way. We may insert dummy questions (if you are still reading these questions, choose choice a) that do have a clear right answer so make sure that test subjects are actually reading the questions, not answering randomly, etc. 
  how_will_you_aggregate_the_results_from_the_crowd: Given the results from CrowdFlower, we will aggregate based on which groups people were in (i.e., if they were primed or not), and then analyze the data testing for a statistically significant difference between the two groups. We will most likely test for priming on different subjects, so there will be many groups to split the data into to determine if priming had an effect, and if so, which priming strategies were most effective.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: 1. we write priming exercises, test questions, instructions, etc.<p>2. automatically generate permutations for questions, priming strategies, etc. for workers to answer to test which methods are most effective<p>3. crowd performs priming exercise, answers questions <p>4. we extract data on people's answering pattens, if they were primed, if so, how, etc<p>5. we analyze data to determine patterns in workers' responses and if these are correlated to certain priming methods, and if there is a significant enough difference to say that these differences are caused by priming 
  how_will_you_evaluate_if_your_project_is_successful: Like in step 5, we determine if any of our test methods are priming were effective enough to influence workers' answers, and if so, which were most effective. 
  what_potential_problems_do_you_foresee_when_implementing_your_project: Since these jobs are two-part, workers may not be motivated to finish the entire job. It is also hard to control for other factors that may be influencing people's decisions (outside of being primed by our priming exercises). Even if there is a noticeable difference between the primed answers vs. control group's answers, it may be hard to conclude that this is a result of our priming exercise. 
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108012935
  name_of_your_project: The Prisoners' Dilemma
  give_a_one_sentence_description_of_your_project: We will be testing the prisoner's dilemma using crowdflower workers, and see if we can influence the results by appealing to a sense of community among workers.
  what_problem_does_it_solve: This problem shows how people will act when their decisions affect others' outcomes, and when others have influence over their outcomes. To add to this classic experiment, we will test whether workers are more inclined to be cooperative and interested in their partner's outcome if we can instill a sense of community among workers beforehand, making each individual worker less inclined to take advantage of their partner. 
  what_similar_projects_exist: Projects implementing the prisoners' dilemma exist. While I was working on hits on mechanical turk, I did a project that tested if there was, in fact, a sense of community among workers (the experiment essentially asked if as a worker, I felt stealing from a worker was more wrong than stealing from someone who is posting the jobs). Our project will work to combine the two. 
  what_type_of_project_is_it: Social science experiment with the crowd
  who_will_be_the_members_of_your_crowd: CrowdFlower workers
  how_will_you_incentivize_them_to_participate: We will pay workers to answer our questions. The questions are pretty straight forward, so there is not a lot of room for us to try to make the questions more interesting/engaging to incentivize workers to participate, but on the other hand, they should be able to answer the questions fairly quickly, which is a good incentive when trying to maximize hits/hour. 
  what_will_they_provide_and_what_sort_of_skills_do_they_need: The questions are fairly straight forward, so no prior experience is necessary. Something we may consider is testing certain workers who have been using crowdflower for a while, have done a certain amount of hits, etc., since these workers may be more inclined to feel the sense of community or loyalty to workers that we are testing for. 
  how_will_you_ensure_the_quality_of_the_crowd_provides: We are trying to show that if there is a stronger sense of community, then workers are more likely to pick the choice that is best for them and their counterpart (not just for them), so we will check if this is true (especially in the case of more experienced workers, workers who claim to feel a sense of loyalty/community, etc.). 
  how_will_you_aggregate_the_results_from_the_crowd: We will analyze people's responses collected from crowdflower. If we ask follow up questions such as how long have you been working for crowdflower, do you feel a sense of community, how many hits have you performed, etc., we will also disaggregate data based on those criteria to see if workers who answered yes to these questions were more likely to respond in certain ways. 
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: 1. write prisoners dilemma problem setup<p>2. write optional add in about sense of community among workers (only to be included with certain hits)<p>3. write questions about sense of community among workers (to be included before or after, on for certain workers, to test the effectiveness of each strategy) <p>4. workers answer the question(s) <p>5. we analyze results, look for correlations between responses and what was included in the prompts workers were given, their responses to additional questions, etc. 
  how_will_you_evaluate_if_your_project_is_successful: Our project will be successful if we can show that a sense a community does or does not exist, and if we can show that we can make people more aware of this community (or make them believe that one exists at all) based on the prompt, preliminary or follow up questions, etc. Basically, if we can show that there are different results based on the type of prompt, then the project is successful. 
  what_potential_problems_do_you_foresee_when_implementing_your_project: A lot of this is contingent on the workers reading a prompt, but it is hard to verify that the worker did not just skip past the instructions and move straight to the questions. There also may be other confounding factors that influence how people respond to the prisoners' dilemma, if they feel a sense of community amongst their fellow workers, etc. that will make it hard to determine if we have actually been able to influence these feeling of loyalty. 
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108313533
  name_of_your_project: Enterovirus D68 tracker
  give_a_one_sentence_description_of_your_project: We are tracking the spread of Enterovirus D68 using social media, specifically through Twitter and Facebook. 
  what_problem_does_it_solve: The project solves the problem of tracking a highly contagious disease. This is a current health scare because an Enterovirus D68 outbreak has been spreading in the United States since August. The disease has spread from the American midwest to many more states and even into Canada. Often, news outlets are late in determining the location of new cases and many focus only on a small region. Furthermore, news outlets may have difficulty in confirming cases due to rules about sharing medical information. However, many people will post about their illnesses to social media, and this can be used to track the spread of Enterovirus D68.
  what_similar_projects_exist: Mark Dredze at JHU is leading a project called Digital Disease Surveillance&#58; influenza. It has produced a system that can estimate the daily or weekly prevalence of influenza in a geographic location based on the normalized volume of Twitter messages (tweets) that indicate an influenza infection. This is very similar to what we hope to achieve, except that we are tracking Enterovirus D68 and that we hope to combine data from two major social media platforms - Twitter and Facebook. Also, a professor at Penn, Lyle Ungar, is developing technology that will estimate variation in subjective well-being over time and space from social media word use. Here is a link to his work&#58; http://www.cis.upenn.edu/~ungar/CVs/WWBP.html. Healthmap (http://www.healthmap.org/en/) also provides tracking of diseases, but without the use of social media. 
  what_type_of_project_is_it: Human computation algorithm
  who_will_be_the_members_of_your_crowd: Workers on Crowdflower and the twitter/facebook users who post.
  how_will_you_incentivize_them_to_participate: The workers will be paid a predetermined amount for each instance of social media output that they analyze. 
  what_will_they_provide_and_what_sort_of_skills_do_they_need: The workers will read a Facebook status or tweet from Twitter and will decide whether it is about a specific instance of an enterovirus infection (i.e. 11 year old boy in michigan has enterovirus) or whether it discusses enterovirus for some other reason (i.e. new treatments being studied for enterovirus).
  how_will_you_ensure_the_quality_of_the_crowd_provides: We will create many test questions on Crowdflower that will serve as a baseline. Workers will first have to pass a quiz with these test questions and any worker who answers a large percent of them incorrectly will be disqualified. In our test questions, we will have 50 tweets/facebook posts about specific cases of enterovirus and 50 tweets/facebook posts that are otherwise related to enterovirus. 
  how_will_you_aggregate_the_results_from_the_crowd: Once we get the results from Crowdflower, we will sort out the tweets/facebook posts about specific instance of enterovirus. Based on this information, we will create a second task that asks workers to determine where (location) the tweet is from. 
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: 1. We will extract a number of tweets and facebook posts with the hashtag #enterovirus. This hashtag has been trending in light of the recent outbreak. We will get tweets and facebook posts from early August (when the outbreak began) all the way to the present.<p>2. We will create a HIT that asks workers to sort the tweets/facebook posts on whether they are a) about specific instances of enterovirus or b) discuss some other aspect of enterovirus<p>3. Based on the tweets/facebook posts that fall into category a from step 2, we will create a second HIT that asks workers to either determine the location of tweet/facebook post. 
  how_will_you_evaluate_if_your_project_is_successful: We will compare the date of a tweet/facebook post to the location that workers attributed to it in step 3. Using this data, we will try to generate a map that shows the movement of the virus over time. We will then compare this to CDC press releases about the spread of the virus. 
  what_potential_problems_do_you_foresee_when_implementing_your_project: 1. We're not sure (yet) how to extract tweets/facebook posts <p>2. Workers might have difficulty with the definitions of what constitutes a post about a specific case of enterovirus<p>3. We might not be able to gather location data if it is not present/public<p>Probably a lot more - if a professor at JHU has a whole team and a lot of time dedicated to this type of research, we will probably have many, many problems that we haven't even thought of yet. 
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108423505
  name_of_your_project: Note Turker
  give_a_one_sentence_description_of_your_project: The purpose of Note Turker is to provide its users with detailed lecture notes from their recorded lectures online.
  what_problem_does_it_solve: Taking detailed notes for a class in real time can be difficult, but lectures often include important material that is not necessarily covered in readings. Note Turker would provide detailed notes for lectures allowing its users to quickly review the material covered in a lecture without having to rewatch said lecture. 
  what_similar_projects_exist: CastingWords is similar in that it’s a crowdsourcing transcription project, but ours goes beyond simply transcription. For our project, we will have the crowd take notes, rather than transcribe. 
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: Crowdflower workers
  how_will_you_incentivize_them_to_participate: Monetary incentive, knowledge.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: Workers will have to look at video clips and determine where breakpoints in the video are (i.e. change of topic, new problem, transition, etc). Workers will then be given short video clips and have to take notes on these clips (we will do these in parallel in order to get the best individual notes, and then in series in order to make those notes the best possible). We discussed that it would likely be better if workers had some previous knowledge of the subjects in the recorded lectures, but it is not entirely necessary given that they are simply taking notes, not doing problems.
  how_will_you_ensure_the_quality_of_the_crowd_provides: We will have the first round of notes taken in parallel and then voted on by the workers in order to ensure that the notes that workers are improving in series have a good starting point. The workers will then vote with each edit of the notes in order to insure their quality. 
  how_will_you_aggregate_the_results_from_the_crowd: Each clip will have a detailed set of notes after the workers work in parallel/series, and then the notes from those clips will be aggregated in order to form notes for the lecture as a whole. 
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: The user either uploads a lecture video or provides the link to the lecture video, and we automatically break the video up into 5 minute clips. Workers then receive these 5 minute clips and are asked to enter the time (minutes and seconds) of each transition in the lecture, or to say that there are no transitions. The lecture is then broken up by those transition times into a series of smaller videos that do not abruptly stop in the middle of an idea. Workers receive these new clips, and are asked to take notes on these clips (in parallel). The notes are then given ratings by workers, and the notes with the highest rating are sent off to the next stage, where workers add to them in series. If none of the notes have a rating above a certain threshold that we will decide, then more notes are taken in parallel (this is for quality control). Once the notes are done in series (maybe after 2-3 more workers add to them), they are aggregated with the rest of the notes from the other clips in that lecture, making one large set of notes. 
  how_will_you_evaluate_if_your_project_is_successful: If we are able to collect notes that are helpful and ideally virtually indistinguishable from the notes of a student actually taking the class, then our project will be successful. 
  what_potential_problems_do_you_foresee_when_implementing_your_project: We are unsure whether or not the background knowledge of a worker will have a large adverse effect on the quality of the notes that the workers will produce, but if it does, it is unlikely that the workers will have experience in the topics of the specific lectures given and may have trouble taking quality notes. We are also worried that cutting the lecture into smaller segments may make the notes harder to understand, but think it’s unrealistic for workers to sit and watch lectures for an hour. 
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108601861
  name_of_your_project: PictureThis
  give_a_one_sentence_description_of_your_project: Collect sequences of pictures from picture books, and have Turkers rewrite the story solely based on the picture given on each page.
  what_problem_does_it_solve: This project does not solve a problem, but it serves three main purposes. The first purpose is to simply run an experiment to see how closely correlated the actual text corresponding to a picture within a picture book is to the text generated by crowd workers who are only shown the pictures. The second purpose is to determine if this correlation is affected by adding context. This would be done by having a crowd worker write a caption for the picture based on the complete sequence of pictures, compared to crowd workers writing a caption for each picture individually without being exposed to the rest of the pictures. The final purpose of the project is to see what kind of creative children stories a crowd can create using the pictures as a base building block.
  what_similar_projects_exist: As far as my research indicates, no similar project has been done in the past.
  what_type_of_project_is_it: Social science experiment with the crowd, Creativity Tool
  who_will_be_the_members_of_your_crowd: Workers on CrowdFlower or MTurk
  how_will_you_incentivize_them_to_participate: Monetary incentives will be used, with different jobs offering crowd workers different levels of compensation depending on the time and effort that goes into each type of task.
  what_will_they_provide_and_what_sort_of_skills_do_they_need: The crowd workers will not need any high level skills—they simply need to be fluent in English and to have a little creativity. They will mainly be completing two kinds of tasks. The first kind of task would be to separate the picture and text from each page of the children’s book. This could be achieved by presenting the crowd workers with an e-book or pdf file, where they have to screenshot the picture, and type the text into a form. The second kind of task would be to present a picture (or series of pictures) to the worker, and have them write a part of the story based on what is going on in the picture.
  how_will_you_ensure_the_quality_of_the_crowd_provides: In order to ensure the quality of the work in the first step, we can have 3-5 workers perform the task of separation independently, and then present these results along with the original file they were given, and have a different set of workers vote on the one with the highest quality. The second task mainly relies on creativity and is thus more subjective. For this reason, rather than combine independent results and ask for the best one, it may be more useful to post the picture and worker-written part of the story in a new task, and have workers vote on whether or not they think the part of the story written is adequate and descriptive, or if it is completely unrelated.
  how_will_you_aggregate_the_results_from_the_crowd: As stated above, each step of the process will consist of several workers answering the same questions or performing the same tasks. After the first step, all results for a given post will be aggregated programmatically, and recombined to create new tasks. These tasks will be checked for quality as stated above, and the results from the “quality-checking tasks” will result in a series of votes that determine which picture and text separation has the highest quality. For the second part we can present a story (written by crowd workers—either singular or plural), and the corresponding pictures to a new set of workers who will vote on whether or not the story makes sense. These votes can be counted programmatically and presented in the results section of the project.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: The steps involved in the process are outlined above, but for the sake of clarity, they have been written as a list below.<p>1.	Build a database of children’s books. Ideally this database will be composed of books that have a single picture on each page, and one or two sentences associated with that picture.<p>2.	Request that crowd workers separate the picture and text on each page by having them screenshot the picture, and type in the text. Each task should be done by 3-5 workers.<p>3.	Place all versions of a specific page’s separation into a new database.<p>4.	Request that crowd workers vote on which separation has the highest quality in the sense that the picture is clear, and there are no typos in the transcription.<p>5.	Create two new types of tasks for each book.<p>a.	Post tasks that consist of a single picture from a book that asks the worker to describe this part of the story in 1-2 sentences based only on that single picture.<p>b.	Post tasks that consist of all the pictures from a book and ask a worker to write the whole story (with 1-2 sentences corresponding to each picture) based on the complete sequence of pictures.<p>6.	Store the results separately (keep the text written by workers who were given a single picture separate from the text written by workers who were given the complete sequence of pictures).<p>7.	Have workers vote on the best “story” written in each format. This means that the pictures and the text from the tasks in 5a will be compiled and a worker can go through all pictures and choose between 3-5 options of corresponding text to create the most coherent story. This will also be independently done with the tasks from 5b. No data collected from 5a will mix with data collected from 5b, so that we can keep the two data sets separate until the end.<p>8.	Once we have the best crowd worker written story from the data in 5a and 5b for each book, we will present the best story from 5a, the best story from 5b, and the actual story, and ask workers to vote on which they like best. An alternative would be to have them rank how closely the best story from 5a is related to the actual story on a 10-point scale, and how closely the best story from 5b is related to the actual story on a 10-point scale.<p>9.	An algorithm will aggregate the data from part 8 so that the findings can be presented. Additionally, a few especially creative stories will be presented to show the class that a children’s book can (or can’t) be written by a crowd.<p>
  how_will_you_evaluate_if_your_project_is_successful: We can evaluate if our project is successful in three ways. The first is if it helps us determine if pictures in a children’s book are related closely enough to the text, that a person can guess what the text is based on the picture alone. The second way is if it helps us determine how important context is in this case—this can be determined by comparing the stories that result from the 5a procedure to those that result from the 5b procedure. The third way is if this experiment actually produces creative children’s books that are worth reading.
  what_potential_problems_do_you_foresee_when_implementing_your_project: It might be difficult to build the initial database of children’s books that we use to conduct the experiment. It is unclear if we will be able to automate the collection of such a database, or if we will have to manually find a selection of books that are available for free and can be used in this manner. We also anticipate difficulties with the phrasing of the requests described above. From our experience as an MTurker, this kind of task does not exist, so we would have to be fairly descriptive and clear with our instructions, as workers may find the task confusing. We imagine it will take some initial trial and error until we find the description that provides the most effective way to obtain the desired results.
-
  provide_a_link_to_your_vimeo_video: https://vimeo.com/108601862
  name_of_your_project: MySelfie
  give_a_one_sentence_description_of_your_project: The purpose of Myself-ie is to help users select their best photos for online dating services.
  what_problem_does_it_solve: People of all ages are now more open to using online dating services, with the latest and most popular amongst the younger demographic being Tinder. Since these platforms are dependent on first impressions, picking the right profile picture is pivotal to success. Myself-ie will ensure users pick the best picture of themselves possible
  what_similar_projects_exist: There is a lot of information about the perfect Tinder picture on the internet, but it has not been put into practice. 
  what_type_of_project_is_it: A business idea that uses crowdsourcing
  who_will_be_the_members_of_your_crowd: Crowdflower/mturk workers
  how_will_you_incentivize_them_to_participate: Monetary incentive
  what_will_they_provide_and_what_sort_of_skills_do_they_need: <p>They will be presented with a series of pictures of the user, then the worker will be asked to hierarchically arrange them in order of attractiveness and dating success. They don’t really need any skill, except each turker will be asked to asses the sex they are attracted to, which will be asked at the beginning. <p>
  how_will_you_ensure_the_quality_of_the_crowd_provides: We will ask several turkers to make the ordering of the same person. That way we can aggregate the result and give a more accurate rendition.
  how_will_you_aggregate_the_results_from_the_crowd: Everyone is going to have the same number of pictures, so the aggregated ordering will just be what picture was voted to be in a given position the most times.
  describe_each_of_the_steps_involved_in_your_process_what_parts_will_be_done_by_the_crowd_and_what_parts_will_be_done_automatically: A person submits up to 10 pictures to get evaluated from the crowd. We then send out the pictures and perform the rankings by the workers. Then automatically, the results will be aggregated and we will provide the user with a finalized hierarchy
  how_will_you_evaluate_if_your_project_is_successful: If the user gets more attention on dating platforms after he amends his profile picture to the one suggested
  what_potential_problems_do_you_foresee_when_implementing_your_project: The main problem is that looks and what is considered attractive are extremely subjective. In addition, these crowdsourcing sources such as Mturk and crowdflower have a lot of people of different races and cultures, so this could skew the results and not provide a definitive outcome.
